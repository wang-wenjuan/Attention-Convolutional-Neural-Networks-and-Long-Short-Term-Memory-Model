{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oyorzKBSARMN",
    "outputId": "653b19d2-eb37-4730-86ff-19d34a422c16"
   },
   "source": [
    "#@title mount\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd \"/content/drive/MyDrive/Colab Notebooks/植被覆盖率预测\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111,
     "referenced_widgets": [
      "d170e34cf84b4e6d811f3556c74ea538",
      "a4e1b6941394474cbf357949a6ae423d",
      "30599db4a19242f396817949719f7ccc",
      "be3cb6229dc544689098f92bf6048e8e",
      "de3860177e0940048a8401af436add2d",
      "b27606bf646d4ac7bb22ca534e62be91",
      "dabdc29e9d9b46ceafde530e293ae2a3",
      "a05dd1c9fe1f4ad7a88c44a965cadc2c",
      "284c2506a24b47a9a8d9de494379aa98"
     ]
    },
    "id": "aB5lmNqTkq1Y",
    "outputId": "a11ccb25-7c7f-4adf-9cc5-e0ad521b75f1"
   },
   "source": [
    "#@title selece model and map\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# 定义全局变量\n",
    "model_type = None\n",
    "map_type = None\n",
    "\n",
    "# 创建下拉菜单\n",
    "model_dropdown = widgets.Dropdown(\n",
    "    options=['CNN', 'LSTM', 'CNNLSTM', 'Attention', 'ViT_Trans', 'ViT_LSTM'],\n",
    "    description='Model:'\n",
    ")\n",
    "\n",
    "map_dropdown = widgets.Dropdown(\n",
    "    options=['FVC', 'LULC', 'RSEI'],\n",
    "    description='Map Type:'\n",
    ")\n",
    "\n",
    "# 创建按钮\n",
    "confirm_button = widgets.Button(description='Confirm')\n",
    "\n",
    "# 显示控件\n",
    "display(model_dropdown, map_dropdown, confirm_button)\n",
    "\n",
    "# 定义训练函数\n",
    "def train_model(model, map_t):\n",
    "    global model_type, map_type  # 使用 global 关键字声明全局变量\n",
    "    model_type = model\n",
    "    map_type = map_t\n",
    "\n",
    "# 绑定按钮点击事件\n",
    "confirm_button.on_click(lambda b: train_model(model_dropdown.value, map_dropdown.value))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-tBk6SdNit5O",
    "outputId": "7b687eec-b553-4bc2-cc14-762c4de91122"
   },
   "source": [
    "print(model_type, map_type)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361,
     "referenced_widgets": [
      "24d50d926d414d2e8feed09f80e1c449",
      "bc01875cbac941cf8614de49d2437722",
      "3eae1c1dce084203aee4ff79e1e16c1e",
      "1e8e90ba89234e5ebd90a9bea285d44e",
      "e035909437034f2e88eb2821a1f6da14",
      "49afc2ef49c7412cbe57a13d2df93d41",
      "6a91af40b4354f03b12bc896977600bc",
      "a993cc466ca94b42ab529dc406f94de7",
      "1d5a6557cf0846d2811911c39ad8325f",
      "7ff4dc4397d447cfa6c7bf12ba40b627",
      "2337f72d267845bcadc6617ceb2dd154",
      "42a6a5af31734b1b97d6144fefd10614",
      "77709b3edb264d16a5a7b065daa3f8ef",
      "f9f17e309db64c95b58240c805de1bdb",
      "fafb6e07fe5141d69c9403e859fc5ba1",
      "97cd252d78c54533b3762095a4872907",
      "f6ed26607130489f9e9a8982855bacc8",
      "1e20b10c753641b09c97aa862d261d24",
      "1c8496f4007f4a93bd7c877aa359f542",
      "17ce8b44829f4f799eeceea2d3150051",
      "a418faefb2ce450a8b8b92808fef2e06",
      "b3dd574545174b1ab696b6526b34907b"
     ]
    },
    "id": "vBsUWzVZHoyL",
    "outputId": "b7e799b6-618c-498c-c709-17438521dce5"
   },
   "source": [
    "#@title load data\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "class MyDataSet(Dataset):\n",
    "    def __init__(self, data, mask, seed, window_size=15, region_size=10, sample_size=100000, split_ratios=(0.8, 0.1, 0.1), subset='train'):\n",
    "        \"\"\"\n",
    "        自定义数据集类，用于动态生成数据，排除所有标签值为0的点。\n",
    "\n",
    "        参数：\n",
    "        - data: 输入的三维数据 (年数, 高, 宽)，形状为 (20, 4416, 5786)\n",
    "        - mask: 二维蒙版 (4416, 5786)，值为0表示对应位置固定为零，不用于训练\n",
    "        - window_size: 用于预测的历史年份数，默认为6\n",
    "        - region_size: 输入区域大小，默认为10\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.mask = mask\n",
    "        self.seed = seed\n",
    "        self.subset = subset\n",
    "        self.sample_size = sample_size\n",
    "        self.split_ratios = split_ratios\n",
    "        self.window_size = window_size\n",
    "        self.region_size = region_size\n",
    "        self.height, self.width = data.shape[1], data.shape[2]\n",
    "        self.year_range = data.shape[0] - window_size  # 可用的年份范围\n",
    "        self.offset = region_size // 2\n",
    "        self.sampler = None\n",
    "\n",
    "        # 根据mask找到所有有效的 (row, col) 坐标\n",
    "        self.valid_spatial_indices = self._get_valid_spatial_indices()\n",
    "\n",
    "        self.class_dict = {}\n",
    "        if subset == 'train':\n",
    "          self.sampler = self.compute_class_weights()\n",
    "\n",
    "        # 按 split_ratios 划分训练集、验证集和测试集\n",
    "\n",
    "    def _get_valid_spatial_indices(self):\n",
    "        \"\"\"\n",
    "        根据mask筛选出所有可能的非零标签点的 (row, col) 坐标\n",
    "        打乱顺序，再顺序切片出需要的样本数\n",
    "        再对应的训练集、验证集和测试集进行划分\n",
    "        \"\"\"\n",
    "        # indices = []\n",
    "        # for i in tqdm(range(self.offset, self.height - self.offset)):\n",
    "        #     for j in range(self.offset, self.width - self.offset):\n",
    "        #         # 如果mask为1，表示该位置可以有非零标签\n",
    "        #         if self.mask[i, j] != 0:\n",
    "        #             indices.append((i, j))\n",
    "\n",
    "        # 提取非零坐标数组\n",
    "        indices = np.nonzero(self.mask[self.offset:self.height - self.offset, self.offset:self.width - self.offset])\n",
    "        indices = list(zip(indices[0] + self.offset, indices[1] + self.offset))\n",
    "\n",
    "        # print(self.data.shape, len(indices))\n",
    "        # indices_array = np.array(indices)\n",
    "        # extracted_data = self.data[:, indices_array[:, 0], indices_array[:, 1]]\n",
    "        # print(extracted_data.shape)\n",
    "\n",
    "        random.seed(self.seed)\n",
    "        random.shuffle(indices)\n",
    "        print(f\"Valid spatial indices({self.subset}) done\")\n",
    "        print('\\tAll indices:', len(indices))\n",
    "        indices = indices[:self.sample_size]\n",
    "        print(f'\\tSelected indices:', len(indices))\n",
    "\n",
    "        train_split = int(self.split_ratios[0] * len(indices))\n",
    "        val_split = int(self.split_ratios[1] * len(indices)) + train_split\n",
    "\n",
    "        if self.subset == 'train':\n",
    "          train_indices = indices[:train_split]\n",
    "          print(\"\\tTraining samples:\", len(train_indices))\n",
    "          return train_indices\n",
    "        elif self.subset == 'val':\n",
    "          val_indices = indices[train_split:val_split]\n",
    "          print(\"\\tValidation samples:\", len(val_indices))\n",
    "          return val_indices\n",
    "        elif self.subset == 'test':\n",
    "          test_indices = indices[val_split:]\n",
    "          print(\"\\tTesting samples:\", len(test_indices))\n",
    "          return test_indices\n",
    "\n",
    "    def compute_class_weights(self):\n",
    "        \"\"\"\n",
    "        统计训练集的类别数量并计算类别权重。\n",
    "        \"\"\"\n",
    "        for year_idx in tqdm(range(self.window_size, self.year_range + self.window_size), desc='Calculating weight...'):\n",
    "            for row, col in self.valid_spatial_indices:\n",
    "                label = self.data[year_idx, row, col] - 1  # 获取标签\n",
    "                if label in self.class_dict:\n",
    "                    self.class_dict[label] += 1\n",
    "                else:\n",
    "                    self.class_dict[label] = 1\n",
    "\n",
    "        # 计算权重：总样本数除以每个类别的数量\n",
    "        total_count = sum(self.class_dict.values())\n",
    "        self.class_weights = {label: total_count / count for label, count in self.class_dict.items()}\n",
    "\n",
    "        print(\"Class counts:\", self.class_dict)\n",
    "        print(\"Class weights:\", self.class_weights)\n",
    "        sample_weights = []\n",
    "        for year_idx in tqdm(range(self.window_size, self.year_range + self.window_size), desc='Assigning weight...'):\n",
    "            for row, col in self.valid_spatial_indices:\n",
    "                label = self.data[year_idx, row, col] - 1  # 获取标签\n",
    "                sample_weights.append(self.class_weights[label])\n",
    "\n",
    "        # 创建加权随机采样器\n",
    "        sampler = WeightedRandomSampler(\n",
    "            weights=sample_weights,\n",
    "            num_samples=len(sample_weights),\n",
    "            replacement=True\n",
    "        )\n",
    "        return sampler\n",
    "\n",
    "    def get_classes(self):\n",
    "        return self.class_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        # 数据集的长度是年份数乘以有效的空间位置数\n",
    "        return self.year_range * len(self.valid_spatial_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 根据数据集索引确定 year 和 (row, col) 的位置\n",
    "        spatial_idx = idx % len(self.valid_spatial_indices)\n",
    "        year_idx = idx // len(self.valid_spatial_indices) + self.window_size\n",
    "        row, col = self.valid_spatial_indices[spatial_idx]\n",
    "\n",
    "        # 根据年份和坐标获取实际输入数据 (window_size, region_size, region_size)\n",
    "        input_data = self.data[year_idx - self.window_size:year_idx,\n",
    "                               row - self.offset:row + self.offset + 1,\n",
    "                               col - self.offset:col + self.offset + 1]\n",
    "\n",
    "        # 获取标签 (目标年份的中心点值)\n",
    "        label_data = self.data[year_idx, row, col]-1\n",
    "        if label_data in self.class_dict.keys():\n",
    "          self.class_dict[label_data] += 1\n",
    "        else:\n",
    "          self.class_dict[label_data] = 1\n",
    "\n",
    "        # 转换为Tensor\n",
    "        input_tensor = torch.tensor(input_data, dtype=torch.float32)\n",
    "        label_tensor = torch.tensor(label_data, dtype=torch.long)\n",
    "        return input_tensor, label_tensor\n",
    "\n",
    "# 读取 npz 文件并加载数据\n",
    "fvc_data = np.load(f'{map_type}.npz')['arr_0']\n",
    "# fvc_data = data['arr_0']\n",
    "mask = np.load('whole_mask.npz')['arr_0']\n",
    "# print(fvc_data.shape)  # 确认数据形状为 (20, 4416, 5786)\n",
    "\n",
    "print(\"Loading data done\")\n",
    "\n",
    "# 创建Dataset实例并使用DataLoader按批次加载数据\n",
    "seed = random.randint(0, 100000)\n",
    "sample_size = 200000\n",
    "train_dataset = MyDataSet(fvc_data, mask, seed, subset='train', sample_size=sample_size)\n",
    "val_dataset = MyDataSet(fvc_data, mask, seed, subset='val', sample_size=sample_size)\n",
    "test_dataset = MyDataSet(fvc_data, mask, seed, subset='test', sample_size=sample_size)\n",
    "\n",
    "sampler = train_dataset.sampler\n",
    "\n",
    "# for i in tqdm(train_dataset):\n",
    "#   continue\n",
    "#   # if int(i[1]) == 0:\n",
    "#     # continue\n",
    "#   # print(i[0].shape, i[1])\n",
    "\n",
    "# print(seed)\n",
    "# print(train_dataset.show_class())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5JhF15-A1H-"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jUn-NDTCHzKJ"
   },
   "source": [
    "#@title CNN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PureCNNModel(nn.Module):\n",
    "    def __init__(self, map_type):\n",
    "        super(PureCNNModel, self).__init__()\n",
    "\n",
    "        # 卷积层\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=0, stride=2)  # 输入1通道，输出32通道\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=0, stride=2)  # 输入32通道，输出64通道\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        # Dropout层\n",
    "        self.dropout_conv = nn.Dropout2d(0.5)  # 卷积层后的Dropout\n",
    "\n",
    "        # 计算展平后的维度\n",
    "        self.flat_dim = 64 * 2 * 2  # 假设输入大小为11x11，经过卷积后展平\n",
    "\n",
    "        # 全连接层\n",
    "        if map_type == \"LULC\":\n",
    "            self.fc = nn.Linear(self.flat_dim, 8)  # 映射到8个分类\n",
    "        else:\n",
    "            self.fc = nn.Linear(self.flat_dim, 6)  # 映射到6个分类\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, time_steps, width, height = x.shape  # x.shape = [batch_size, time_steps, 11, 11]\n",
    "\n",
    "        # 合并时间步到批次维度\n",
    "        x = x.view(batch_size * time_steps, 1, width, height)  # [batch_size * time_steps, 1, 11, 11]\n",
    "\n",
    "        # CNN提取特征\n",
    "        x = torch.relu(self.bn1(self.conv1(x)))\n",
    "        x = torch.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.dropout_conv(x)\n",
    "\n",
    "        # 展平\n",
    "        x = x.view(batch_size * time_steps, -1)  # 展平 [batch_size * time_steps, flat_dim]\n",
    "\n",
    "        # 全连接层\n",
    "        x = self.fc(x)  # 映射到分类 [batch_size * time_steps, num_classes]\n",
    "\n",
    "        # 恢复批次和时间步的分离\n",
    "        x = x.view(batch_size, time_steps, -1)  # [batch_size, time_steps, num_classes]\n",
    "\n",
    "        # 平均时间步的分类结果\n",
    "        x = x.mean(dim=1)  # [batch_size, num_classes]\n",
    "\n",
    "        return x\n",
    "\n",
    "# model = PureCNNModel(map_type=map_type)\n",
    "# input_tensor = torch.randn(32, 15, 11, 11)  # 假设批次大小为32，时间步为15\n",
    "# output_tensor = model(input_tensor)\n",
    "# print(\"Output shape:\", output_tensor.shape)  # 输出应为 [32, num_classes]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KRxJSOg-Fs37"
   },
   "source": [
    "#@title LSTM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PureLSTMModel(nn.Module):\n",
    "    def __init__(self, map_type, input_dim=11 * 11, hidden_size=128, num_layers=2, num_classes=6):\n",
    "        super(PureLSTMModel, self).__init__()\n",
    "\n",
    "        # LSTM 层\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # 分类层\n",
    "\n",
    "        if map_type == \"LULC\":\n",
    "            self.fc = nn.Linear(hidden_size, 8)  # 映射到8个分类\n",
    "        else:\n",
    "            self.fc = nn.Linear(hidden_size, 6)  # 映射到6个分类\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, time_steps, width, height = x.shape  # x.shape = [batch_size, time_steps, 11, 11]\n",
    "\n",
    "        # 将每个时间步展平成一维特征\n",
    "        x = x.view(batch_size, time_steps, -1)  # shape = [batch_size, time_steps, 11 * 11]\n",
    "\n",
    "        # 使用 LSTM 提取序列特征\n",
    "        lstm_out, _ = self.lstm(x)  # lstm_out shape = [batch_size, time_steps, hidden_size]\n",
    "\n",
    "        # 取 LSTM 的最后一个时间步的输出\n",
    "        x = lstm_out[:, -1, :]  # shape = [batch_size, hidden_size]\n",
    "\n",
    "        # 分类\n",
    "        x = self.fc(x)  # shape = [batch_size, num_classes]\n",
    "\n",
    "        return x\n",
    "\n",
    "# # 测试模型结构\n",
    "# model = PureLSTMModel(map_type=map_type)\n",
    "# input_tensor = torch.randn(32, 15, 11, 11)  # 假设批量大小为32\n",
    "# output_tensor = model(input_tensor)\n",
    "# print(\"Output shape:\", output_tensor.shape)  # 输出应为 [32, 6]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NidooQmkA2HF"
   },
   "source": [
    "#@title CNNLSTM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNN_LSTM_Model(nn.Module):\n",
    "    def __init__(self, map_type):\n",
    "        super(CNN_LSTM_Model, self).__init__()\n",
    "        # 卷積層\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=0, stride=2)  # 每個時間步輸入1通道，輸出32通道\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=0, stride=2)  # 輸入32通道，輸出64通道\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        # Dropout層\n",
    "        self.dropout_conv = nn.Dropout2d(0.5)  # 卷積層之後的Dropout\n",
    "\n",
    "        # 計算展平後的維度: 128 * 11 * 11\n",
    "        # self.flat_dim = 64 * 11 * 11\n",
    "        self.flat_dim = 64 * 2 * 2\n",
    "\n",
    "        # LSTM層，用於處理序列數據\n",
    "        self.lstm = nn.LSTM(input_size=self.flat_dim, hidden_size=128, num_layers=1, batch_first=True)\n",
    "\n",
    "        # 全連接層\n",
    "        if map_type == \"LULC\":\n",
    "          self.fc = nn.Linear(128, 8)  # 將LSTM的最後一個時間步的輸出映射到8個分類\n",
    "        else:\n",
    "          self.fc = nn.Linear(128, 6)  # 將LSTM的最後一個時間步的輸出映射到6個分類\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, time_steps, width, height = x.shape  # x.shape = [8192, 15, 11, 11]\n",
    "\n",
    "        # 將時間步合併到批次維度，進行批量卷積操作\n",
    "        x = x.view(batch_size * time_steps, 1, width, height)  # shape = [batch_size * time_steps, 1, 11, 11]\n",
    "\n",
    "        # CNN提取空間特徵\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        # x = self.bn1(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        # x = self.bn2(x)\n",
    "        x = self.dropout_conv(x)\n",
    "        # print(x.shape)\n",
    "\n",
    "        # 展平\n",
    "        x = x.view(batch_size, time_steps, -1)  # shape = [batch_size, time_steps, flat_dim]\n",
    "        # print(x.shape)\n",
    "\n",
    "        # 使用LSTM處理序列數據\n",
    "        lstm_out, _ = self.lstm(x)  # lstm_out shape = [batch_size, time_steps, 128]\n",
    "        # print(lstm_out.shape)\n",
    "\n",
    "        # 取LSTM的最後一個時間步的輸出\n",
    "        x = lstm_out[:, -1, :]  # shape = [batch_size, 128]\n",
    "\n",
    "        # 全連接層進行分類\n",
    "        x = self.fc(x)  # shape = [batch_size, 6]\n",
    "\n",
    "        return x\n",
    "\n",
    "# # 测试模型结构\n",
    "# model = CNN_LSTM_Model(map_type=map_type)\n",
    "# # input_tensor = torch.randn(32, 15, 11, 11)  # 假设批量大小为32\n",
    "# # output_tensor = model(input_tensor)\n",
    "# # print(\"Output shape:\", output_tensor.shape)  # 输出应为 [32, 6]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bA-Q5xIy4_uJ"
   },
   "source": [
    "#@title ConvLSTM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, kernel_size):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
    "\n",
    "        # 卷积层：用于计算 LSTM 的输入门、遗忘门、输出门和候选状态\n",
    "        self.conv_i = nn.Conv2d(input_size + hidden_size, hidden_size, kernel_size=kernel_size, padding=self.padding)\n",
    "        self.conv_f = nn.Conv2d(input_size + hidden_size, hidden_size, kernel_size=kernel_size, padding=self.padding)\n",
    "        self.conv_o = nn.Conv2d(input_size + hidden_size, hidden_size, kernel_size=kernel_size, padding=self.padding)\n",
    "        self.conv_g = nn.Conv2d(input_size + hidden_size, hidden_size, kernel_size=kernel_size, padding=self.padding)\n",
    "\n",
    "    def forward(self, x, h, c):\n",
    "        # 拼接输入和上一时刻的隐藏状态\n",
    "        combined = torch.cat([x, h], dim=1)\n",
    "\n",
    "        # 计算 LSTM 的四个门\n",
    "        i = torch.sigmoid(self.conv_i(combined))  # 输入门\n",
    "        f = torch.sigmoid(self.conv_f(combined))  # 遗忘门\n",
    "        o = torch.sigmoid(self.conv_o(combined))  # 输出门\n",
    "        g = torch.tanh(self.conv_g(combined))     # 候选状态\n",
    "\n",
    "        # 更新细胞状态\n",
    "        c_new = f * c + i * g\n",
    "\n",
    "        # 计算新的隐藏状态\n",
    "        h_new = o * torch.tanh(c_new)\n",
    "\n",
    "        return h_new, c_new\n",
    "\n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, kernel_size, num_layers, output_size):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # 初始化多个 ConvLSTM 层\n",
    "        self.layers = nn.ModuleList([\n",
    "            ConvLSTMCell(input_size if i == 0 else hidden_size, hidden_size, kernel_size)\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # 最后一层的输出会输入到全连接层进行分类\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, time_steps, _, width, height = x.size()\n",
    "\n",
    "        # 初始化细胞状态和隐藏状态\n",
    "        h, c = [torch.zeros(batch_size, self.hidden_size, width, height).to(x.device) for _ in range(2)]\n",
    "\n",
    "        # 逐步处理每个时间步的数据\n",
    "        for t in range(time_steps):\n",
    "            x_t = x[:, t]  # 获取当前时间步的输入数据\n",
    "\n",
    "            # 在每一层 ConvLSTM 上进行前向传播\n",
    "            for layer in range(self.num_layers):\n",
    "                h, c = self.layers[layer](x_t, h, c)\n",
    "\n",
    "            # 当前时刻的输出\n",
    "            x_t = h  # 当前时刻的隐藏状态作为下一个时间步的输入\n",
    "\n",
    "        # 最后一层的输出经过全连接层分类\n",
    "        x_t = x_t.view(batch_size, -1)  # 展平为一维\n",
    "        out = self.fc(x_t)  # 预测输出\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ConvLSTM_Model(nn.Module):\n",
    "    def __init__(self, input_channels=1, hidden_size=64, kernel_size=(3, 3), num_layers=2, output_size=6):\n",
    "        super(ConvLSTM_Model, self).__init__()\n",
    "\n",
    "        # 定义ConvLSTM层\n",
    "        self.conv_lstm = ConvLSTM(input_size=input_channels, hidden_size=hidden_size,\n",
    "                                  kernel_size=kernel_size, num_layers=num_layers, output_size=output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape = [batch_size, time_steps, channels, height, width]\n",
    "        out = self.conv_lstm(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "# # 测试模型结构\n",
    "# model = ConvLSTM_Model(input_channels=1, hidden_size=64, kernel_size=(3, 3), num_layers=2, output_size=6)\n",
    "# input_tensor = torch.randn(32, 15, 1, 11, 11)  # 假设批量大小为32，15个时间步，1通道，11x11空间\n",
    "# output_tensor = model(input_tensor)\n",
    "# print(\"Output shape:\", output_tensor.shape)  # 输出应为 [32, 6]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SOgAzFL-B-IU",
    "cellView": "form"
   },
   "source": [
    "#@title Attention\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TemporalAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(TemporalAttention, self).__init__()\n",
    "        self.attn_weights = nn.Parameter(torch.randn(hidden_size, 1))  # 用于计算每个时间步的注意力权重\n",
    "\n",
    "    def forward(self, lstm_out):\n",
    "        # lstm_out shape = [batch_size, time_steps, hidden_size]\n",
    "        attn_scores = torch.bmm(lstm_out, self.attn_weights.unsqueeze(0).expand(lstm_out.size(0), -1, -1))  # (batch_size, time_steps, 1)\n",
    "        attn_weights = torch.softmax(attn_scores, dim=1)  # 计算每个时间步的注意力权重\n",
    "        context = torch.sum(attn_weights * lstm_out, dim=1)  # 加权求和，得到时间步的上下文向量\n",
    "        return context\n",
    "\n",
    "class CNN_LSTM_Attention_Model(nn.Module):\n",
    "    def __init__(self, map_type):\n",
    "        super(CNN_LSTM_Attention_Model, self).__init__()\n",
    "\n",
    "        # 卷积层\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=0, stride=2)  # 每个时间步输入1通道，输出32通道\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=0, stride=2)  # 输入32通道，输出64通道\n",
    "\n",
    "        # BatchNorm层\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        # Dropout层\n",
    "        self.dropout_conv = nn.Dropout2d(0.5)  # 卷积层之后的Dropout\n",
    "\n",
    "        # 计算展平后的维度: 64 * 2 * 2\n",
    "        self.flat_dim = 64 * 2 * 2\n",
    "\n",
    "        # LSTM层，用于处理序列数据\n",
    "        self.lstm = nn.LSTM(input_size=self.flat_dim, hidden_size=128, num_layers=1, batch_first=True)\n",
    "\n",
    "        # 时间注意力层\n",
    "        self.attn = TemporalAttention(128)\n",
    "\n",
    "        # 全连接层\n",
    "        if map_type == \"LULC\":\n",
    "            self.fc = nn.Linear(128, 8)  # 将LSTM的最后一个时间步的输出映射到8个分类\n",
    "        else:\n",
    "            self.fc = nn.Linear(128, 8)  # 将LSTM的最后一个时间步的输出映射到6个分类\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, time_steps, width, height = x.shape  # x.shape = [8192, 15, 11, 11]\n",
    "\n",
    "        # 将时间步合并到批次维度，进行批量卷积操作\n",
    "        x = x.view(batch_size * time_steps, 1, width, height)  # shape = [batch_size * time_steps, 1, 11, 11]\n",
    "\n",
    "        # CNN提取空间特征\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.dropout_conv(x)\n",
    "\n",
    "        # 展平\n",
    "        x = x.view(batch_size, time_steps, -1)  # shape = [batch_size, time_steps, flat_dim]\n",
    "\n",
    "        # 使用LSTM处理序列数据\n",
    "        lstm_out, _ = self.lstm(x)  # lstm_out shape = [batch_size, time_steps, 128]\n",
    "\n",
    "        # 使用时间注意力机制提取加权的序列特征\n",
    "        x = self.attn(lstm_out)  # shape = [batch_size, hidden_size]\n",
    "\n",
    "        # 全连接层进行分类\n",
    "        x = self.fc(x)  # shape = [batch_size, 6]\n",
    "\n",
    "        return x\n",
    "\n",
    "# # 测试模型结构\n",
    "# model = CNN_LSTM_Attention_Model(map_type=map_type)\n",
    "# input_tensor = torch.randn(32, 15, 11, 11)  # 假设批量大小为32，15个时间步，11x11的空间\n",
    "# output_tensor = model(input_tensor)\n",
    "# # print(\"Output shape:\", output_tensor.shape)  # 输出应为 [32, 6]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mq8DRoq7rUuK",
    "cellView": "form"
   },
   "source": [
    "#@title ViT_Trans\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Model parameters\n",
    "patch_size = 11  # Each 11x11 grid is a single patch\n",
    "emb_size = 64    # Embedding size\n",
    "seq_len = 15     # Number of time steps\n",
    "num_heads = 4    # Number of attention heads\n",
    "num_layers = 2   # Number of transformer layers\n",
    "\n",
    "# ViT + Transformer 模型定义\n",
    "class ViTTransformer(nn.Module):\n",
    "    def __init__(self, map_type, patch_size=11, emb_size=64, seq_len=15, num_heads=4, num_layers=2):\n",
    "        super(ViTTransformer, self).__init__()\n",
    "\n",
    "        # Patch Embedding for each 11x11 grid (treated as one patch here)\n",
    "        self.patch_size = patch_size\n",
    "        self.emb_size = emb_size\n",
    "        self.patch_embedding = nn.Linear(patch_size * patch_size, emb_size)\n",
    "\n",
    "        # Learnable positional encoding for time steps\n",
    "        self.positional_encoding = nn.Parameter(torch.randn(1, seq_len, emb_size))\n",
    "\n",
    "        # Transformer Encoder for temporal modeling\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=emb_size, nhead=num_heads, batch_first=True),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "\n",
    "        # Classification head\n",
    "\n",
    "        if map_type == \"LULC\":\n",
    "            self.fc = nn.Linear(emb_size, 8)  # 映射到8个分类\n",
    "        else:\n",
    "            self.fc = nn.Linear(emb_size, 8)  # 映射到6个分类\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, H, W) -> (B, T, P)\n",
    "        B, T, H, W = x.size()\n",
    "        assert H == self.patch_size and W == self.patch_size, \"Input size mismatch with patch size\"\n",
    "\n",
    "        # Flatten each patch (11x11 -> 121)\n",
    "        x = x.view(B, T, -1)  # (B, T, P)\n",
    "\n",
    "        # Patch embedding (121 -> emb_size)\n",
    "        x = self.patch_embedding(x)  # (B, T, emb_size)\n",
    "\n",
    "        # Add positional encoding (T -> seq_len)\n",
    "        x = x + self.positional_encoding[:, :T, :]  # (B, T, emb_size)\n",
    "\n",
    "        # Transformer Encoder\n",
    "        x = self.transformer(x)  # (B, T, emb_size)\n",
    "\n",
    "        # Take the last time step for classification\n",
    "        x = x[:, -1, :]  # (B, emb_size)\n",
    "\n",
    "        # Classification\n",
    "        output = self.fc(x)  # (B, num_classes)\n",
    "        return output\n",
    "\n",
    "\n",
    "# model = ViTTransformer(map_type=map_type)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "7Mokchla2z2M"
   },
   "source": [
    "#@title ViT_LSTM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Model parameters\n",
    "patch_size = 11  # Each 11x11 grid is a single patch\n",
    "emb_size = 64    # Embedding size\n",
    "seq_len = 15     # Number of time steps\n",
    "lstm_hidden_size = 128  # LSTM hidden size\n",
    "\n",
    "# ViT + LSTM 模型定义\n",
    "class ViTLSTM(nn.Module):\n",
    "    def __init__(self, map_type, patch_size=11, emb_size=64, seq_len=15, lstm_hidden_size=128):\n",
    "        super(ViTLSTM, self).__init__()\n",
    "\n",
    "        # Patch Embedding for each 11x11 grid (treated as one patch here)\n",
    "        self.patch_size = patch_size\n",
    "        self.emb_size = emb_size\n",
    "        self.patch_embedding = nn.Linear(patch_size * patch_size, emb_size)\n",
    "\n",
    "        # LSTM for temporal modeling\n",
    "        self.lstm = nn.LSTM(emb_size, lstm_hidden_size, batch_first=True)\n",
    "\n",
    "        # Classification head\n",
    "        if map_type == \"LULC\":\n",
    "            self.fc = nn.Linear(lstm_hidden_size, 8)  # 映射到8个分类\n",
    "        else:\n",
    "            self.fc = nn.Linear(lstm_hidden_size, 6)  # 映射到6个分类\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, H, W) -> (B, T, P)\n",
    "        B, T, H, W = x.size()\n",
    "        assert H == self.patch_size and W == self.patch_size, \"Input size mismatch with patch size\"\n",
    "\n",
    "        # Flatten each patch (11x11 -> 121)\n",
    "        x = x.view(B, T, -1)  # (B, T, P)\n",
    "\n",
    "        # Patch embedding (121 -> emb_size)\n",
    "        x = self.patch_embedding(x)  # (B, T, emb_size)\n",
    "\n",
    "        # LSTM for temporal modeling\n",
    "        x, (hn, cn) = self.lstm(x)  # (B, T, lstm_hidden_size)\n",
    "\n",
    "        # Take the last time step for classification (or use the final hidden state)\n",
    "        x = x[:, -1, :]  # (B, lstm_hidden_size)\n",
    "\n",
    "        # Classification\n",
    "        output = self.fc(x)  # (B, num_classes)\n",
    "        return output\n",
    "\n",
    "# # Example usage\n",
    "# model = ViTLSTM(map_type=map_type)\n",
    "\n",
    "# # Example input\n",
    "# x = torch.randn(32, 15, 11, 11)  # Batch size 32, 15 time steps, 11x11 grid\n",
    "# output = model(x)\n",
    "# print(output.shape)  # Expected: torch.Size([32, 6])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "GWNjCHnXc1Mn"
   },
   "source": [
    "#@title COA\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class CoatiOptimization:\n",
    "    def __init__(self, model, objective_function, param_bounds, population_size=20, max_iterations=50):\n",
    "        \"\"\"\n",
    "        初始化Coati优化算法\n",
    "        :param model: 待优化的模型\n",
    "        :param objective_function: 评估模型性能的目标函数\n",
    "        :param param_bounds: 参数边界，字典形式 {param_name: (min_value, max_value)}\n",
    "        :param population_size: 水獭个体数量\n",
    "        :param max_iterations: 最大迭代次数\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.objective_function = objective_function\n",
    "        self.param_bounds = param_bounds\n",
    "        self.population_size = population_size\n",
    "        self.max_iterations = max_iterations\n",
    "        self.population = self.initialize_population()\n",
    "\n",
    "    def initialize_population(self):\n",
    "        \"\"\"随机初始化水獭群体参数\"\"\"\n",
    "        population = []\n",
    "        for _ in range(self.population_size):\n",
    "            individual = {param: np.random.uniform(low, high) for param, (low, high) in self.param_bounds.items()}\n",
    "            population.append(individual)\n",
    "        return population\n",
    "\n",
    "    def optimize(self):\n",
    "        \"\"\"执行Coati优化算法\"\"\"\n",
    "        for iteration in range(self.max_iterations):\n",
    "            # 评估每个水獭个体的适应度\n",
    "            fitness = [self.objective_function(self.model, individual) for individual in self.population]\n",
    "            # 根据适应度排序\n",
    "            sorted_population = [x for _, x in sorted(zip(fitness, self.population), key=lambda pair: pair[0])]\n",
    "\n",
    "            # 更新水獭的参数（模拟捕食行为）\n",
    "            best_individual = sorted_population[0]\n",
    "            for i, individual in enumerate(self.population):\n",
    "                for param in individual:\n",
    "                    # 模拟水獭追捕猎物的行为（简单调整参数）\n",
    "                    step = (best_individual[param] - individual[param]) * np.random.rand()\n",
    "                    individual[param] += step\n",
    "                    # 确保参数在边界内\n",
    "                    individual[param] = np.clip(individual[param], *self.param_bounds[param])\n",
    "        return best_individual\n",
    "\n",
    "\n",
    "def objective_function(model, params):\n",
    "    \"\"\"\n",
    "    用于优化的目标函数。\n",
    "\n",
    "    参数：\n",
    "    - params: 字典，包含需要优化的超参数。\n",
    "\n",
    "    返回：\n",
    "    - 验证集损失或指标值（如准确率）。\n",
    "    \"\"\"\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "    # 模型初始化\n",
    "    model = update_model_with_params(model, params)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # 定义损失函数和优化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # 训练模型\n",
    "    num_epochs = 5\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs_batch, labels_batch in tqdm(train_loader, desc=f\"train {epoch}\", leave=False):\n",
    "            inputs_batch, labels_batch = inputs_batch.to(device), labels_batch.to(device)\n",
    "\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 前向传播\n",
    "            outputs = model(inputs_batch)\n",
    "\n",
    "            # 计算损失\n",
    "            loss = criterion(outputs, labels_batch)\n",
    "\n",
    "            # 反向传播和优化\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "    # 验证模型\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs_batch, labels_batch in tqdm(val_loader, desc=f\"val_{epoch}\", leave=False):\n",
    "            inputs_batch, labels_batch = inputs_batch.to(device), labels_batch.to(device)\n",
    "\n",
    "            # 前向传播\n",
    "            outputs = model(inputs_batch)\n",
    "            loss = criterion(outputs, labels_batch)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # 计算准确率\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels_batch).sum().item()\n",
    "            total += labels_batch.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # 返回验证集损失（用于最小化）\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "\n",
    "def update_model_with_params(model, best_params):\n",
    "    \"\"\"\n",
    "    根据最佳参数更新模型结构\n",
    "    :param model: 原始模型实例\n",
    "    :param best_params: Coati优化得到的最佳参数\n",
    "    :return: 更新后的模型\n",
    "    \"\"\"\n",
    "    # 更新CNN层\n",
    "    model.conv1 = nn.Conv2d(\n",
    "        1,\n",
    "        int(best_params['conv1_out_channels']),\n",
    "        kernel_size=int(best_params['kernel_size']),\n",
    "        stride=2\n",
    "    )\n",
    "    model.conv2 = nn.Conv2d(\n",
    "        int(best_params['conv1_out_channels']),\n",
    "        int(best_params['conv2_out_channels']),\n",
    "        kernel_size=int(best_params['kernel_size']),\n",
    "        stride=2\n",
    "    )\n",
    "\n",
    "    # 更新展平维度计算 (需要重新推断卷积后的形状)\n",
    "    dummy_input = torch.randn(1, 1, 11, 11)  # 假设输入为[batch_size, channel, height, width]\n",
    "    dummy_output = model.conv2(model.conv1(dummy_input))\n",
    "    flat_dim = int(torch.prod(torch.tensor(dummy_output.shape[1:])))  # 计算展平后的维度\n",
    "\n",
    "    # 更新LSTM层\n",
    "    model.flat_dim = flat_dim\n",
    "    model.lstm = nn.LSTM(\n",
    "        input_size=model.flat_dim,\n",
    "        hidden_size=int(best_params['lstm_hidden_size']),\n",
    "        num_layers=1,\n",
    "        batch_first=True\n",
    "    )\n",
    "\n",
    "    # 更新全连接层的输入大小为LSTM的隐藏层大小\n",
    "    model.fc = nn.Linear(\n",
    "        in_features=int(best_params['lstm_hidden_size']),\n",
    "        out_features=model.fc.out_features  # 分类数保持不变\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# param_bounds = {\n",
    "#     'conv1_out_channels': (16, 64),\n",
    "#     'conv2_out_channels': (32, 128),\n",
    "#     'kernel_size': (2, 5),\n",
    "#     'lstm_input_size': (256, 1024),\n",
    "#     'lstm_hidden_size': (64, 256)\n",
    "# }\n",
    "\n",
    "\n",
    "# # 创建模型实例\n",
    "\n",
    "\n",
    "# # 初始化Coati优化算法\n",
    "# coati_optimizer = CoatiOptimization(\n",
    "#     model=model,\n",
    "#     objective_function=objective_function,\n",
    "#     param_bounds=param_bounds,\n",
    "#     population_size=10,\n",
    "#     max_iterations=10\n",
    "# )\n",
    "\n",
    "\n",
    "# # 优化超参数\n",
    "# best_params = coati_optimizer.optimize()\n",
    "\n",
    "\n",
    "# # 使用最佳参数更新模型\n",
    "# print(\"Best parameters:\", best_params)\n",
    "\n",
    "# model = update_model_with_params(model, best_params)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Y2bAPdanEEo"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YXiQQfJ_ud7J",
    "outputId": "5e04cfb1-b6f0-4d97-d1a8-881690251c63"
   },
   "source": [
    "#@title AMP Train\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_dict = {\n",
    "    \"CNN\": PureCNNModel(map_type=map_type),\n",
    "    \"LSTM\": PureLSTMModel(map_type=map_type),\n",
    "    \"CNNLSTM\": CNN_LSTM_Model(map_type=map_type),\n",
    "    \"Attention\": CNN_LSTM_Attention_Model(map_type=map_type),\n",
    "    \"ViT_Trans\": ViTTransformer(map_type=map_type),\n",
    "    \"ViT_LSTM\": ViTLSTM(map_type=map_type)\n",
    "}\n",
    "\n",
    "model = model_dict[model_type]\n",
    "\n",
    "# 设置训练超参数\n",
    "epochs = 500  # 训练的轮数\n",
    "learning_rate = 0.001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 4096 * 4 * 2\n",
    "\n",
    "num_workers = 2\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler, shuffle=False, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "# 损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()  # 适用于分类任务\n",
    "\n",
    "# 将模型移动到GPU (如果可用)\n",
    "print(device)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.1)\n",
    "\n",
    "# 初始化 GradScaler 用于 AMP\n",
    "scaler = GradScaler('cuda')\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # 遍历训练数据\n",
    "    for inputs_batch, labels_batch in tqdm(train_loader, desc=\"Training...\", leave=False):\n",
    "        inputs_batch, labels_batch = inputs_batch.to(device), labels_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 使用 AMP 进行前向和反向传播\n",
    "        with autocast('cuda'):\n",
    "            outputs = model(inputs_batch)\n",
    "            loss = criterion(outputs, labels_batch)\n",
    "\n",
    "        # Scaler 处理梯度缩放\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # 记录训练损失和准确率\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels_batch.size(0)\n",
    "        correct += (predicted == labels_batch).sum().item()\n",
    "\n",
    "    # 计算训练集的平均损失和准确度\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "\n",
    "    # 验证集上的损失和准确度\n",
    "    model.eval()  # 切换为评估模式\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():  # 禁用梯度\n",
    "        for val_inputs, val_labels in tqdm(val_loader, desc=\"validating...\", leave=False):\n",
    "            val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
    "            with autocast('cuda'):  # 在验证阶段也使用 AMP\n",
    "                val_outputs = model(val_inputs)\n",
    "                val_loss += criterion(val_outputs, val_labels).item()\n",
    "\n",
    "            _, val_predicted = torch.max(val_outputs, 1)\n",
    "            val_total += val_labels.size(0)\n",
    "            val_correct += (val_predicted == val_labels).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "\n",
    "    # 更新学习率调度器\n",
    "    scheduler.step(avg_val_loss)\n",
    "    last_lr = scheduler.get_last_lr()\n",
    "\n",
    "    # 保存训练日志\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    with open(\"models/training_log.txt\", \"a\") as log_file:\n",
    "        log_message = (f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, \"\n",
    "                       f\"Accuracy: {epoch_accuracy:.2f}%, Val Loss: {avg_val_loss:.4f}, \"\n",
    "                       f\"Val Accuracy: {val_accuracy:.2f}%， Learning rate: {last_lr}\\n\")\n",
    "        print(log_message, end='')  # 控制台输出\n",
    "        log_file.write(log_message)  # 写入文件\n",
    "\n",
    "    # 每个epoch后保存模型\n",
    "    if epoch % 10 == 0:\n",
    "        os.makedirs(f\"models/saves/{map_type}/\", exist_ok=True)\n",
    "        model_save_path = f\"models/saves/{map_type}/{model_type}_{epoch+1}_{val_accuracy:.2f}%.pth\"\n",
    "        torch.save(model.state_dict(), model_save_path)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "collapsed": true,
    "id": "awRj5jZ2H021",
    "outputId": "5c7c1ea3-2356-4c79-9000-7eeeca87acc8"
   },
   "source": [
    "#@title Train\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# 设置训练超参数\n",
    "epochs = 500  # 训练的轮数\n",
    "learning_rate = 0.01\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# batch_size = 1024\n",
    "batch_size = 4096 * 4\n",
    "num_workers = 2\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "# 损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()  # 适用于分类任务\n",
    "\n",
    "# 将模型移动到GPU (如果可用)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.1)\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # 遍历训练数据\n",
    "    for inputs_batch, labels_batch in tqdm(train_loader, desc=\"Training...\", leave=False):\n",
    "        inputs_batch, labels_batch = inputs_batch.to(device), labels_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs_batch)\n",
    "        # print(inputs_batch.shape, outputs.shape)\n",
    "        loss = criterion(outputs, labels_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels_batch.size(0)\n",
    "        correct += (predicted == labels_batch).sum().item()\n",
    "\n",
    "    # 计算训练集的平均损失和准确度\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "\n",
    "    # 验证集上的损失和准确度\n",
    "    model.eval()  # 切换为评估模式\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():  # 禁用梯度\n",
    "        for val_inputs, val_labels in tqdm(val_loader, desc=\"validating...\", leave=False):\n",
    "            val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
    "            val_outputs = model(val_inputs)\n",
    "            val_loss += criterion(val_outputs, val_labels).item()\n",
    "\n",
    "            _, val_predicted = torch.max(val_outputs, 1)\n",
    "            val_total += val_labels.size(0)\n",
    "            val_correct += (val_predicted == val_labels).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "    # print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # 更新学习率调度器\n",
    "    scheduler.step(avg_val_loss)\n",
    "    last_lr = scheduler.get_last_lr()\n",
    "\n",
    "    with open(\"models/training_log.txt\", \"a\") as log_file:  # 使用 \"a\" 模式追加写入\n",
    "        # log_message = f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\\n\"\n",
    "        log_message = f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%， Learning rate: {last_lr}\\n\"\n",
    "        print(log_message, end='')  # 控制台输出\n",
    "        log_file.write(log_message)  # 写入文件\n",
    "\n",
    "\n",
    "    # 每个epoch后保存模型\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    model_save_path = f\"models/{epoch+1}.pth\"\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    # print(f\"Model saved at {model_save_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Rju7pUygNwT"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "sJezxMFRihKJ"
   },
   "source": [
    "#@title Test\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "model_dict = {\n",
    "    \"CNN\": PureCNNModel(map_type=map_type),\n",
    "    \"LSTM\": CNN_LSTM_Attention_Model(map_type=map_type),\n",
    "    \"CNNLSTM\": CNN_LSTM_Model(map_type=map_type),\n",
    "    \"Attention\": CNN_LSTM_Attention_Model(map_type=map_type),\n",
    "    \"ViT_Trans\": ViTTransformer(map_type=map_type),\n",
    "    \"ViT_LSTM\": ViTLSTM(map_type=map_type)\n",
    "}\n",
    "\n",
    "model = model_dict[model_type]\n",
    "\n",
    "model.load_state_dict(torch.load(f'models/{map_type}/{model_type}.pth', weights_only=True, map_location=torch.device('cpu')))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "batch_size = 4096 * 4\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "all_targets = []\n",
    "all_outputs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "  for inputs, targets in tqdm(test_loader):\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "    # print(inputs.shape)\n",
    "    outputs = model(inputs)\n",
    "    # print(outputs.shape)\n",
    "    outputs = np.argmax(outputs.cpu(), axis=1)\n",
    "    targets = targets.cpu()\n",
    "    # print(inputs.shape, outputs.shape)\n",
    "\n",
    "    outputs = outputs + 1\n",
    "    targets = targets + 1\n",
    "\n",
    "    all_targets.extend(targets.numpy())\n",
    "    all_outputs.extend(outputs.numpy())\n",
    "\n",
    "\n",
    "plt.rcParams['font.family'] = 'Serif'\n",
    "fontsize = 14\n",
    "title_fontsize = 16\n",
    "\n",
    "# 1. 准确率 (Accuracy)\n",
    "accuracy = accuracy_score(all_targets, all_outputs)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 2. 精确率 (Precision) -  每个类别的精确率\n",
    "precision_macro = precision_score(all_targets, all_outputs, average='macro')\n",
    "precision_micro = precision_score(all_targets, all_outputs, average='micro')\n",
    "precision_weighted = precision_score(all_targets, all_outputs, average='weighted')\n",
    "print(f\"Macro Precision: {precision_macro:.4f}\")\n",
    "print(f\"Micro Precision: {precision_micro:.4f}\")\n",
    "print(f\"Weighted Precision: {precision_weighted:.4f}\")\n",
    "\n",
    "# 3. 召回率 (Recall) - 每个类别的召回率\n",
    "recall_macro = recall_score(all_targets, all_outputs, average='macro')\n",
    "recall_micro = recall_score(all_targets, all_outputs, average='micro')\n",
    "recall_weighted = recall_score(all_targets, all_outputs, average='weighted')\n",
    "print(f\"Macro Recall: {recall_macro:.4f}\")\n",
    "print(f\"Micro Recall: {recall_micro:.4f}\")\n",
    "print(f\"Weighted Recall: {recall_weighted:.4f}\")\n",
    "\n",
    "# 4. F1 分数 (F1-score) -  每个类别的F1分数，是精确率和召回率的调和平均数\n",
    "f1_macro = f1_score(all_targets, all_outputs, average='macro')\n",
    "f1_micro = f1_score(all_targets, all_outputs, average='micro')\n",
    "f1_weighted = f1_score(all_targets, all_outputs, average='weighted')\n",
    "print(f\"Macro F1-score: {f1_macro:.4f}\")\n",
    "print(f\"Micro F1-score: {f1_micro:.4f}\")\n",
    "print(f\"Weighted F1-score: {f1_weighted:.4f}\")\n",
    "\n",
    "# 5. 混淆矩阵 (Confusion Matrix)\n",
    "cm = confusion_matrix(all_targets, all_outputs)\n",
    "# print(\"Confusion Matrix:\\n\", cm)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "labels = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "labels = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# 设置图形大小\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# 使用seaborn绘制热力图\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=labels, yticklabels=labels) # annot=True 显示数值, fmt='d' 保持整数显示\n",
    "\n",
    "# 添加标签和标题\n",
    "plt.xlabel('Predicted Label', fontsize=fontsize)\n",
    "plt.ylabel('True Label', fontsize=fontsize)\n",
    "plt.title('Confusion Matrix', fontsize=title_fontsize)\n",
    "\n",
    "# # tick_marks = np.arange(cm.shape[0]) + 1\n",
    "# plt.xticks(tick_marks, tick_marks)\n",
    "# plt.yticks(tick_marks, tick_marks)\n",
    "\n",
    "# 显示图形\n",
    "os.makedirs(f'outputs/plots/{model_type}/matrix/', exist_ok=True)\n",
    "plt.savefig(f'outputs/plots/{model_type}/matrix/{map_type}_confusion_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "# 绘制百分比混淆矩阵\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\", cbar=False, xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted Label', fontsize=fontsize)\n",
    "plt.ylabel('True Label', fontsize=fontsize)\n",
    "plt.title('Normalized Confusion Matrix', fontsize=title_fontsize)\n",
    "\n",
    "\n",
    "# # tick_marks = np.arange(cm.shape[0]) + 1\n",
    "# plt.xticks(tick_marks, tick_marks)\n",
    "# plt.yticks(tick_marks, tick_marks)\n",
    "\n",
    "plt.savefig(f'outputs/plots/{model_type}/matrix/{map_type}_normalized_confusion_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "# 6. 分类报告 (Classification Report) - 包含精确率，召回率，F1分数\n",
    "report = classification_report(all_targets, all_outputs)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "plt.rcParams['font.family'] = 'Serif'\n",
    "fontsize = 14\n",
    "\n",
    "fvc_class_map = {\n",
    "    0: None,  # 空\n",
    "    1: \"Low vegetation coverage\",  # L\n",
    "    2: \"Relatively low vegetation coverage\",  # RL\n",
    "    3: \"Moderate vegetation coverage\",  # M\n",
    "    4: \"Relatively high vegetation coverage\",  # RH\n",
    "    5: \"High vegetation coverage\",  # H\n",
    "    6: \"blank\",  # 白色像素\n",
    "}\n",
    "\n",
    "lulc_class_map = {\n",
    "    0: None,  # 空\n",
    "    1: \"Cropland\",  # L\n",
    "    2: \"Forest\",  # RL\n",
    "    3: \"Grassland\",  # M\n",
    "    4: \"Water\",  # RH\n",
    "    5: \"Impervious\",  # H\n",
    "    6: \"Barren\",  # 白色像素\n",
    "    7: \"Snow/Ice\",  # 白色像素\n",
    "    8: \"blank\",  # 白色像素\n",
    "}\n",
    "\n",
    "rsei_class_map = {\n",
    "    0: None,  # 空\n",
    "    1: \"Poor\",  # L\n",
    "    2: \"Fair\",  # RL\n",
    "    3: \"Moderate\",  # M\n",
    "    4: \"Good\",  # RH\n",
    "    5: \"Excellent\",  # H\n",
    "    6: \"blank\",  # 白色像素\n",
    "}\n",
    "\n",
    "map_type_map = {\n",
    "    'FVC': fvc_class_map,\n",
    "    'LULC': lulc_class_map,\n",
    "    'RSEI': rsei_class_map,\n",
    "}\n",
    "\n",
    "# 假设类别数为 n_classes\n",
    "n_classes = len(np.unique(all_targets))\n",
    "\n",
    "# 将目标值进行二值化（one-hot 编码）\n",
    "y_bin = label_binarize(all_targets, classes=np.arange(n_classes))\n",
    "y_pred_bin = label_binarize(all_outputs, classes=np.arange(n_classes))\n",
    "\n",
    "# 计算每个类别的 Precision-Recall 曲线和 Average Precision\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "for i in range(1, n_classes):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_bin[:, i], y_pred_bin[:, i])\n",
    "    average_precision[i] = average_precision_score(y_bin[:, i], y_pred_bin[:, i])\n",
    "\n",
    "# 绘制每个类别的 Precision-Recall 曲线\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(1, n_classes):\n",
    "    plt.plot(recall[i], precision[i], label=f'{map_type_map[map_type][i]} (AP = {average_precision[i]:.2f})')\n",
    "\n",
    "plt.xlabel('Recall', fontsize=fontsize)\n",
    "plt.ylabel('Precision', fontsize=fontsize)\n",
    "plt.title('Precision-Recall Curve', fontsize=title_fontsize)\n",
    "plt.legend(loc='best', fontsize=fontsize)\n",
    "plt.grid()\n",
    "os.makedirs(f'outputs/plots/{model_type}/PR/', exist_ok=True)\n",
    "plt.savefig(f'outputs/plots/{model_type}/PR/{map_type}_PR_curve.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# 计算每个类别的 ROC 曲线和 AUC\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(1, n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], y_pred_bin[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# 绘制每个类别的 ROC 曲线\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(1, n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'{map_type_map[map_type][i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
    "plt.xlabel('False Positive Rate', fontsize=fontsize)\n",
    "plt.ylabel('True Positive Rate', fontsize=fontsize)\n",
    "plt.title('ROC Curve', fontsize=title_fontsize)\n",
    "plt.legend(loc='best', fontsize=fontsize)\n",
    "plt.grid()\n",
    "os.makedirs(f'outputs/plots/{model_type}/ROC/', exist_ok=True)\n",
    "plt.savefig(f'outputs/plots/{model_type}/ROC/{map_type}_ROC_curve.png')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "2a95f7b4e252474c8583eb7fd88a6c46",
      "e3c736e0ac6744f68d25edbdac1b1704",
      "d5a75c307e274cee92b7ceaaf5cd9f46",
      "bc84a83c96504941a96fea60c95398ec",
      "d8022dcda62a4531ad867e7d53edd0a7",
      "e55bda5c00f64ca4ad2d8571079da589",
      "891096e8eb894989a6cc7daf6ec585e5",
      "f04d84742cfb4b559782b08d5ce1d84d",
      "0a2feb40efc54bbbbd46719933c900a5",
      "ae0af5ad164e4a4a8c33e8500e6b9b35",
      "48eb7401a6f04d5eb30c506c85390124",
      "0e962ba7126042e79fc4535ce21458dd",
      "554ba37f89ce4d0097b472f3e1864335",
      "850fb100de844941b2ffaf1955f9fc8a",
      "a5aa2ebab9a549ce8613d9ab0ba1f030",
      "3d0409f839ca43fd8575942084eb585b",
      "193c22694a5c4e859c7bd14ecac71662",
      "bd8cd3291bf744f8b50520ef83c8fe79",
      "9c3294508c8d4422b3cfe9fa6e6c0cca",
      "bc0229dffa3c4990a3fd52fef0af273b",
      "4db41b167ab84c96babcfea4e07673fa",
      "a918989cc1404b05974f1206e4c093d9",
      "6df8947776df46609991d4be444de7a8",
      "127332dab12848f59c42a5133ae2c9c0",
      "63f14af70e694cddba182c25f66c642a",
      "618f52167ffc48fab4341bcf5103e2d8",
      "580ed1ee144844fc91c678bec38c6b99",
      "6d044fe1654a40c6b077cc9b1fc40390",
      "443cde3e8b964b818c1399fe30ac9d42",
      "4f93abba8ce54f3880d1f213baed63b6",
      "a3a6993b1d9e4f4e9ea4d359408e01fb",
      "4b0261738dcd4cb7b7d54a41760fdcc6",
      "30a00ad147e24dbaa9f7cf91d9485b75",
      "64ad90e33a2544a8a33ff71ff67618b6",
      "bc193aeb2b9d4170aade328a05085f07",
      "bcdab4a336df49458101bd5875fa4050",
      "91d62dd31bf34f13a910c6517b3c6aac",
      "1839ac209ec147a3bb3b58b5c32a6fa8",
      "eba2d07c1f964ce4ad9d50bb8fdc7d04",
      "ca324e5a48484a248b2ce2ffe55c3fad",
      "b62835cf31984f56bec062e4ed7e83fd",
      "d5022fdf78874478845fc881552cbd06",
      "4f73dd73221f42479b1f02b1ea7a0537",
      "c889807ee6c24d11aa3a0ad101c66499"
     ]
    },
    "id": "0SH3Q2Atg3_a",
    "outputId": "dbf4bad4-c0af-4299-e740-e53879f8ebee"
   },
   "source": [
    "#@title Test All\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "plt.rcParams['font.family'] = 'Serif'\n",
    "# fontsize = 14\n",
    "\n",
    "fvc_class_map = {\n",
    "    0: None,  # 空\n",
    "    1: \"Low\",  # L\n",
    "    2: \"Relatively low\",  # RL\n",
    "    3: \"Moderate\",  # M\n",
    "    4: \"Relatively high\",  # RH\n",
    "    5: \"High\",  # H\n",
    "    6: \"blank\",  # 白色像素\n",
    "}\n",
    "\n",
    "lulc_class_map = {\n",
    "    0: None,  # 空\n",
    "    1: \"Cropland\",  # L\n",
    "    2: \"Forest\",  # RL\n",
    "    3: \"Grassland\",  # M\n",
    "    4: \"Water\",  # RH\n",
    "    5: \"Impervious\",  # H\n",
    "    6: \"Barren\",  # 白色像素\n",
    "    7: \"Snow/Ice\",  # 白色像素\n",
    "    8: \"blank\",  # 白色像素\n",
    "}\n",
    "\n",
    "rsei_class_map = {\n",
    "    0: None,  # 空\n",
    "    1: \"Poor\",  # L\n",
    "    2: \"Fair\",  # RL\n",
    "    3: \"Moderate\",  # M\n",
    "    4: \"Good\",  # RH\n",
    "    5: \"Excellent\",  # H\n",
    "    6: \"blank\",  # 白色像素\n",
    "}\n",
    "\n",
    "map_type_map = {\n",
    "    'FVC': fvc_class_map,\n",
    "    'LULC': lulc_class_map,\n",
    "    'RSEI': rsei_class_map,\n",
    "}\n",
    "\n",
    "model_dict = {\n",
    "    \"CNN\": PureCNNModel(map_type=map_type),\n",
    "    \"LSTM\": PureLSTMModel(map_type=map_type),\n",
    "    # \"LSTM\": CNN_LSTM_Attention_Model(map_type=map_type),\n",
    "    \"CNNLSTM\": CNN_LSTM_Model(map_type=map_type),\n",
    "    \"Attention\": CNN_LSTM_Attention_Model(map_type=map_type),\n",
    "    \"ViT_Trans\": ViTTransformer(map_type=map_type),\n",
    "    \"ViT_LSTM\": ViTLSTM(map_type=map_type)\n",
    "}\n",
    "\n",
    "for model_type in ['CNN', 'LSTM', 'CNNLSTM', 'Attention'][:]:\n",
    "  # print(f\"Testing {map} - {model}\")\n",
    "  print(f\"Testing {map_type} - {model_type}\")\n",
    "  model = model_dict[model_type]\n",
    "  model.load_state_dict(torch.load(f'models/{map_type}/{model_type}.pth', weights_only=True, map_location=torch.device('cpu')))\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "  model.to(device)\n",
    "\n",
    "  batch_size = 4096 * 4\n",
    "  test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "  all_targets = []\n",
    "  all_outputs = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for inputs, targets in tqdm(test_loader):\n",
    "      inputs = inputs.to(device)\n",
    "      targets = targets.to(device)\n",
    "      # print(inputs.shape)\n",
    "      outputs = model(inputs)\n",
    "      # print(outputs.shape)\n",
    "      outputs = outputs[:, :-1]  # 去除白色标签概率\n",
    "      outputs = np.argmax(outputs.cpu(), axis=1)\n",
    "      targets = targets.cpu()\n",
    "\n",
    "      all_targets.extend(targets.numpy())\n",
    "      all_outputs.extend(outputs.numpy())\n",
    "\n",
    "\n",
    "  plt.rcParams['font.family'] = 'Serif'\n",
    "  # title_fontsize = 24\n",
    "  # fontsize = 22\n",
    "  # tick_fontsize = 22\n",
    "  # labelsize = 18\n",
    "  title_fontsize = 32  # 标题\n",
    "  legend_fontsize = 28  # 图例\n",
    "  tick_fontsize = 28  # 坐标刻度\n",
    "  axis_fontsize = 32  # 坐标轴标题\n",
    "  matrix_value_fontsize = 28  # 热力图值标签\n",
    "\n",
    "  with_legend = True\n",
    "\n",
    "  # 1. 准确率 (Accuracy)\n",
    "  accuracy = accuracy_score(all_targets, all_outputs)\n",
    "\n",
    "  # 2. 精确率 (Precision) -  每个类别的精确率\n",
    "  precision_macro = precision_score(all_targets, all_outputs, average='macro')\n",
    "  precision_micro = precision_score(all_targets, all_outputs, average='micro')\n",
    "  precision_weighted = precision_score(all_targets, all_outputs, average='weighted')\n",
    "\n",
    "  # 3. 召回率 (Recall) - 每个类别的召回率\n",
    "  recall_macro = recall_score(all_targets, all_outputs, average='macro')\n",
    "  recall_micro = recall_score(all_targets, all_outputs, average='micro')\n",
    "  recall_weighted = recall_score(all_targets, all_outputs, average='weighted')\n",
    "\n",
    "  # 4. F1 分数 (F1-score) -  每个类别的F1分数，是精确率和召回率的调和平均数\n",
    "  f1_macro = f1_score(all_targets, all_outputs, average='macro')\n",
    "  f1_micro = f1_score(all_targets, all_outputs, average='micro')\n",
    "  f1_weighted = f1_score(all_targets, all_outputs, average='weighted')\n",
    "\n",
    "  # print(f\"Accuracy: {accuracy:.4f}\")\n",
    "  # print()\n",
    "  # print(f\"Macro Precision: {precision_macro:.4f}\")\n",
    "  # print()\n",
    "  # print(f\"Micro Precision: {precision_micro:.4f}\")\n",
    "  # print()\n",
    "  # print(f\"Weighted Precision: {precision_weighted:.4f}\")\n",
    "  # print()\n",
    "  # print(f\"Macro Recall: {recall_macro:.4f}\")\n",
    "  # print()\n",
    "  # print(f\"Micro Recall: {recall_micro:.4f}\")\n",
    "  # print()\n",
    "  # print(f\"Weighted Recall: {recall_weighted:.4f}\")\n",
    "  # print()\n",
    "  # print(f\"Macro F1-score: {f1_macro:.4f}\")\n",
    "  # print()\n",
    "  # print(f\"Micro F1-score: {f1_micro:.4f}\")\n",
    "  # print()\n",
    "  # print(f\"Weighted F1-score: {f1_weighted:.4f}\")\n",
    "\n",
    "  # 5. 混淆矩阵 (Confusion Matrix)\n",
    "  cm = confusion_matrix(all_targets, all_outputs)\n",
    "  cm = cm[:, :-1]\n",
    "\n",
    "  # print(\"Confusion Matrix:\\n\", cm)\n",
    "  cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "  xlabels = list(range(0, len(np.unique(all_targets))-1))\n",
    "  ylabels = list(range(0, len(np.unique(all_targets))))\n",
    "\n",
    "  # 设置图形大小\n",
    "  plt.figure(figsize=(10, 8))\n",
    "\n",
    "  # 使用seaborn绘制热力图\n",
    "  sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=xlabels, yticklabels=ylabels, annot_kws={\"size\": matrix_value_fontsize}) # annot=True 显示数值, fmt='d' 保持整数显示\n",
    "\n",
    "  # 添加标签和标题\n",
    "  plt.xlabel('Predicted Label', fontsize=axis_fontsize)\n",
    "  plt.ylabel('True Label', fontsize=axis_fontsize)\n",
    "  plt.title('Confusion Matrix', fontsize=title_fontsize)\n",
    "  legend_labels = [mpatches.Patch(color='white', label=f'{i}: {map_type_map[map_type][i+1]}') for i in ylabels]\n",
    "\n",
    "  # plt.legend(handles=legend_labels, loc='upper right', title='Labels', fontsize=10, title_fontsize=10)\n",
    "  if with_legend:\n",
    "    plt.legend(handles=legend_labels, bbox_to_anchor=(1.8, 0.9), title='Labels', fontsize=legend_fontsize, title_fontsize=legend_fontsize)\n",
    "\n",
    "  plt.xticks(fontsize=tick_fontsize)\n",
    "  plt.yticks(fontsize=tick_fontsize)\n",
    "\n",
    "  # 显示图形\n",
    "  os.makedirs(f'outputs/plots/{model_type}/matrix/', exist_ok=True)\n",
    "  plt.savefig(f'outputs/plots/{model_type}/matrix/{map_type}_confusion_matrix.png', bbox_inches='tight')\n",
    "  # plt.show()\n",
    "\n",
    "  # 绘制百分比混淆矩阵\n",
    "  plt.figure(figsize=(10, 8))\n",
    "  sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\", cbar=False, xticklabels=xlabels, yticklabels=ylabels, annot_kws={\"size\": matrix_value_fontsize})\n",
    "  plt.xlabel('Predicted Label', fontsize=axis_fontsize)\n",
    "  plt.ylabel('True Label', fontsize=axis_fontsize)\n",
    "  plt.title('Normalized Confusion Matrix', fontsize=title_fontsize)\n",
    "  if with_legend:\n",
    "    plt.legend(handles=legend_labels, bbox_to_anchor=(1.8, 0.9), title='Labels', fontsize=legend_fontsize, title_fontsize=legend_fontsize)\n",
    "\n",
    "\n",
    "  # # tick_marks = np.arange(cm.shape[0]) + 1\n",
    "  plt.xticks(fontsize=tick_fontsize)\n",
    "  plt.yticks(fontsize=tick_fontsize)\n",
    "\n",
    "  plt.savefig(f'outputs/plots/{model_type}/matrix/{map_type}_normalized_confusion_matrix.png', bbox_inches='tight')\n",
    "  # plt.show()\n",
    "\n",
    "  # 6. 分类报告 (Classification Report) - 包含精确率，召回率，F1分数\n",
    "  report = classification_report(all_targets, all_outputs, output_dict=True)\n",
    "  report_df = pd.DataFrame(report).transpose()\n",
    "  # print(\"Classification Report:\\n\", report)\n",
    "  os.makedirs(f'outputs/plots/{model_type}/Report/', exist_ok=True)\n",
    "  report_df.to_csv(f'outputs/plots/{model_type}/Report/{map_type}_Report.csv', index=True)\n",
    "\n",
    "\n",
    "  # 假设类别数为 n_classes\n",
    "  n_classes = len(np.unique(all_targets))-1\n",
    "\n",
    "  # 将目标值进行二值化（one-hot 编码）\n",
    "  y_bin = label_binarize(all_targets, classes=np.arange(n_classes))\n",
    "  y_pred_bin = label_binarize(all_outputs, classes=np.arange(n_classes))\n",
    "\n",
    "  # 计算每个类别的 Precision-Recall 曲线和 Average Precision\n",
    "  precision = dict()\n",
    "  recall = dict()\n",
    "  average_precision = dict()\n",
    "  for i in range(0, n_classes):\n",
    "      precision[i], recall[i], _ = precision_recall_curve(y_bin[:, i], y_pred_bin[:, i])\n",
    "      average_precision[i] = average_precision_score(y_bin[:, i], y_pred_bin[:, i])\n",
    "\n",
    "  # 绘制每个类别的 Precision-Recall 曲线\n",
    "  plt.figure(figsize=(10, 8))\n",
    "  for i in range(0, n_classes):\n",
    "      # plt.plot(recall[i], precision[i], label=f'{map_type_map[map_type][i+1]} (AP = {average_precision[i]:.2f})')\n",
    "      plt.plot(recall[i], precision[i], label=f'{map_type_map[map_type][i+1]}')\n",
    "\n",
    "  plt.xlabel('Recall', fontsize=axis_fontsize)\n",
    "  plt.ylabel('Precision', fontsize=axis_fontsize)\n",
    "  plt.tick_params(axis='x', labelsize=tick_fontsize)\n",
    "  plt.tick_params(axis='y', labelsize=tick_fontsize)\n",
    "  plt.title('Precision-Recall Curve', fontsize=title_fontsize)\n",
    "  if with_legend:\n",
    "    plt.legend(loc='best', fontsize=legend_fontsize, bbox_to_anchor=(1.6, 0.9))\n",
    "  plt.grid()\n",
    "  os.makedirs(f'outputs/plots/{model_type}/PR/', exist_ok=True)\n",
    "  plt.savefig(f'outputs/plots/{model_type}/PR/{map_type}_PR_curve.png', bbox_inches='tight')\n",
    "  # plt.show()\n",
    "\n",
    "\n",
    "  from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "  # 计算每个类别的 ROC 曲线和 AUC\n",
    "  fpr = dict()\n",
    "  tpr = dict()\n",
    "  roc_auc = dict()\n",
    "  for i in range(0, n_classes):\n",
    "      fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], y_pred_bin[:, i])\n",
    "      roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "  # 绘制每个类别的 ROC 曲线\n",
    "  plt.figure(figsize=(10, 8))\n",
    "  for i in range(0, n_classes):\n",
    "      # plt.plot(fpr[i], tpr[i], label=f'{map_type_map[map_type][i+1]} (AUC = {roc_auc[i]:.2f})')\n",
    "      plt.plot(fpr[i], tpr[i], label=f'{map_type_map[map_type][i+1]}')\n",
    "\n",
    "  plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
    "  plt.xlabel('False Positive Rate', fontsize=axis_fontsize)\n",
    "  plt.ylabel('True Positive Rate', fontsize=axis_fontsize)\n",
    "  plt.tick_params(axis='x', labelsize=tick_fontsize)\n",
    "  plt.tick_params(axis='y', labelsize=tick_fontsize)\n",
    "  plt.title('ROC Curve', fontsize=title_fontsize)\n",
    "  if with_legend:\n",
    "    plt.legend(loc='best', fontsize=legend_fontsize, bbox_to_anchor=(1.6, 0.9))\n",
    "  plt.grid()\n",
    "  os.makedirs(f'outputs/plots/{model_type}/ROC/', exist_ok=True)\n",
    "  plt.savefig(f'outputs/plots/{model_type}/ROC/{map_type}_ROC_curve.png', bbox_inches='tight')\n",
    "  # plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SqrzCU03hcz"
   },
   "source": [
    "# Graph gen"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GmJH1rib3liX",
    "outputId": "ad55823d-98fa-42c9-def8-66c40bcd2774"
   },
   "source": [
    "# 导入必要的包\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_dict = {\n",
    "    \"CNN\": PureCNNModel(map_type=map_type),\n",
    "    \"LSTM\": CNN_LSTM_Attention_Model(map_type=map_type),\n",
    "    \"CNNLSTM\": CNN_LSTM_Model(map_type=map_type),\n",
    "    \"Attention\": CNN_LSTM_Attention_Model(map_type=map_type),\n",
    "    \"ViT_Trans\": ViTTransformer(map_type=map_type),\n",
    "    \"ViT_LSTM\": ViTLSTM(map_type=map_type)\n",
    "}\n",
    "\n",
    "# 加载保存的模型\n",
    "model = model_dict[model_type].to(device)\n",
    "print(f'models/{map_type}/{model_type}.pth')\n",
    "model.load_state_dict(torch.load(f'models/{map_type}/{model_type}.pth', weights_only=True))\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vj3DdR2vD20-"
   },
   "source": [
    "## data process"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "id": "o2LwYPpq8qkw"
   },
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 载入数据并提取最后15年的数据\n",
    "fvc_data = np.load(f'{map_type}.npz')['arr_0']\n",
    "mask = np.load('whole_mask.npz')['arr_0']\n",
    "latest_15_years_data = fvc_data[-15:]  # 提取最后15年的数据，形状为 (15, 4416, 5786)\n",
    "\n",
    "predicted_map = np.zeros(latest_15_years_data.shape[1:])  # 初始化一个数组来保存预测结果\n",
    "\n",
    "mask = np.load('whole_mask.npz')['arr_0']\n",
    "\n",
    "# 设置区域大小\n",
    "region_size = 10\n",
    "offset = region_size // 2\n",
    "height, width = latest_15_years_data.shape[1:]\n",
    "\n",
    "\n",
    "indices = np.nonzero(mask[offset:height - offset, offset:width - offset])\n",
    "indices = list(zip(indices[0] + offset, indices[1] + offset))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tb-wwjszgAaM"
   },
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_dLBZlTBa2X",
    "outputId": "ce9f04ad-25cd-4ce1-ffa1-73e58036c4a3"
   },
   "source": [
    "import torch\n",
    "\n",
    "model.eval()  # 切换模型到评估模式\n",
    "# 批量大小\n",
    "batch_size = 1024 * 8 * 2  # 可以尝试调整批量大小，根据设备内存情况选择合适的数值\n",
    "\n",
    "# 初始化结果数组\n",
    "predicted_map = np.zeros(latest_15_years_data.shape[1:], dtype=np.uint8)\n",
    "\n",
    "# 将 indices 划分为批次\n",
    "batches = [indices[i:i + batch_size] for i in range(0, len(indices), batch_size)]\n",
    "\n",
    "# 遍历每个批次\n",
    "for batch in tqdm(batches):\n",
    "    # 构造批量输入\n",
    "    input_batch = []\n",
    "    for i, j in batch:\n",
    "        input_data = latest_15_years_data[:, i - offset:i + offset + 1, j - offset:j + offset + 1]\n",
    "        input_batch.append(input_data)\n",
    "\n",
    "    # 转换为 Tensor 并移动到设备\n",
    "    input_tensor = torch.tensor(np.array(input_batch), dtype=torch.float32).to(device)  # 形状为 (batch_size, 15, 11, 11)\n",
    "\n",
    "    # 执行批量预测\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)\n",
    "        # 去除白色像素\n",
    "        outputs = outputs[:, :-1]\n",
    "        _, predicted_classes = torch.max(outputs, 1)  # 获取预测的类别\n",
    "        # print(outputs)\n",
    "        # print(outputs[:-1])\n",
    "\n",
    "    # 将预测结果写入预测地图\n",
    "    for (i, j), predicted_class in zip(batch, predicted_classes):\n",
    "        predicted_map[i, j] = predicted_class.item() + 1  # 提取数值并写入最终结果\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MneeoF-VgCoO"
   },
   "source": [
    "## show plot"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iejWHEJsZdIg",
    "outputId": "e30caf1e-eb97-450c-e61e-f44712ae10a6"
   },
   "source": [
    "from google.colab.patches import cv2_imshow\n",
    "import cv2\n",
    "\n",
    "\n",
    "fvc_color_map = {\n",
    "    0: [0, 0, 0],  # 空\n",
    "    1: [0, 56, 168],  # L\n",
    "    2: [0, 115, 38],  # H\n",
    "    3: [82, 142, 249],  # RL\n",
    "    4: [103, 203, 134],  # RH\n",
    "    5: [190, 255, 255],  # M\n",
    "    6: [255, 255, 255],  # 白色像素\n",
    "}\n",
    "\n",
    "lulc_color_map = {\n",
    "    0: [0, 0, 0],  # 空\n",
    "    1: [115, 255, 255],  # Cropland\n",
    "    2: [0, 168, 112],  # Forest\n",
    "    3: [190, 255, 233],  # Grassland\n",
    "    4: [230, 92, 0],  # Water\n",
    "    5: [0, 76, 230],  # Impervious\n",
    "    6: [52, 52, 52],  # Barren\n",
    "    7: [204, 204, 204],  # Snow/Ice\n",
    "    8: [255, 255, 255],  # 白色像素\n",
    "}\n",
    "\n",
    "rsei_color_map = {\n",
    "    0: [0, 0, 0],  # 空\n",
    "    1: [0, 0, 255],  # Poor\n",
    "    2: [0, 128, 255],  # Fair\n",
    "    3: [0, 255, 255],  # Moderate\n",
    "    4: [0, 212, 141],  # Good\n",
    "    5: [0, 168, 56],  # Excellent\n",
    "    6: [255, 255, 255],  # 白色像素\n",
    "}\n",
    "\n",
    "map_type_map = {\n",
    "    'FVC': fvc_color_map,\n",
    "    'LULC': lulc_color_map,\n",
    "    'RSEI': rsei_color_map,\n",
    "}\n",
    "\n",
    "def img_2d_to_3d_vector(int_image, map_type):\n",
    "    \"\"\"\n",
    "    将整数表示的图像转换为RGB图像\n",
    "\n",
    "    :param int_image: h*w 的图像np数组，表示整数图像\n",
    "    :param map_type: 字符串，(fvc/lulc/rsei)\n",
    "    :return: h*w*3 的图像np数组，表示RGB图像。返回None如果颜色映射中没有找到对应的颜色。\n",
    "    \"\"\"\n",
    "    h, w = int_image.shape\n",
    "    try:\n",
    "        color_map = map_type_map[map_type]\n",
    "        rgb_values = np.array(list(color_map.values()))\n",
    "        int_values = np.array(list(color_map.keys()))\n",
    "\n",
    "        # 创建一个与int_image形状相同的数组，用于存储RGB值\n",
    "        rgb_image = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "        # 使用广播和np.where进行向量化操作\n",
    "        for i, int_val in enumerate(int_values):\n",
    "            rgb_image[int_image == int_val] = rgb_values[i]\n",
    "        rgb_image = background_2_white(rgb_image, 20)\n",
    "        return rgb_image\n",
    "    except KeyError:\n",
    "        print(\"颜色映射中没有找到对应的颜色。\")\n",
    "        return None\n",
    "\n",
    "def background_2_white(image, line_width):\n",
    "    # Step 1: 创建黑色部分的蒙版\n",
    "    # 黑色像素定义为所有通道都为 0\n",
    "    mask = np.all(image == [0, 0, 0], axis=-1).astype(np.uint8)  # 二值蒙版，黑色为1\n",
    "\n",
    "    # Step 2: 腐蚀蒙版\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (line_width, line_width))  # 定义腐蚀核\n",
    "    eroded_mask = cv2.erode(mask, kernel, iterations=1)  # 腐蚀操作\n",
    "\n",
    "    # Step 3: 替换蒙版区域为白色\n",
    "    # 将腐蚀后的蒙版区域设为白色\n",
    "    result_image = image.copy()\n",
    "    result_image[eroded_mask == 1] = [255, 255, 255]  # 替换为白色\n",
    "    return result_image\n",
    "\n",
    "rgb_image = img_2d_to_3d_vector(predicted_map, map_type)\n",
    "cv2_imshow(img_2d_to_3d_vector(latest_15_years_data[-1], map_type))\n",
    "cv2_imshow(img_2d_to_3d_vector(latest_15_years_data[-2], map_type))\n",
    "cv2_imshow(rgb_image)\n",
    "cv2.imwrite(f'outputs/{map_type}_{model_type}_predicted_map.png', rgb_image)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rHTzfppdaPQ-"
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UlNVbM5udEsQ"
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def get_listed_colormap(map_type):\n",
    "    \"\"\"\n",
    "    根据提供的颜色映射表创建mcolors.ListedColormap\n",
    "\n",
    "    :param map_type: 字符串，'FVC', 'LULC', 或 'RSEI' 表示所需的颜色映射表\n",
    "    :return: mcolors.ListedColormap 对象\n",
    "    \"\"\"\n",
    "    # Check if the map_type exists in the map_type_map dictionary\n",
    "    if map_type in map_type_map:\n",
    "        # Extract the color map\n",
    "        color_map = map_type_map[map_type]\n",
    "\n",
    "        # Extract RGB values and normalize them to [0, 1] for matplotlib\n",
    "        rgb_values = np.array(list(color_map.values())) / 255.0\n",
    "        rgb_values[:, [0, 2]] = rgb_values[:, [2, 0]]\n",
    "        # print(rgb_values.shape)\n",
    "        # Create and return a ListedColormap\n",
    "        return mcolors.ListedColormap(rgb_values, name=map_type)\n",
    "    else:\n",
    "        print(\"指定的 map_type 不存在于颜色映射中。\")\n",
    "        return None\n",
    "\n",
    "def plot_color_mapped_image(int_image, map_type):\n",
    "    \"\"\"\n",
    "    根据整数图像及其颜色映射，在plt上绘制出对应的RGB图像\n",
    "\n",
    "    :param int_image: h*w 的图像np数组，表示整数图像\n",
    "    :param map_type: 字符串，(fvc/lulc/rsei)\n",
    "    \"\"\"\n",
    "    rgb_image = img_2d_to_3d_vector(int_image, map_type)\n",
    "    if rgb_image is not None:\n",
    "        plt.imshow(rgb_image)\n",
    "        plt.axis('off')  # 隐藏坐标轴\n",
    "        plt.title(f'{map_type} Color Mapped Image')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"无法绘制图像，因为颜色映射中没有找到对应的颜色。\")\n",
    "\n",
    "# plot_color_mapped_image(predicted_map, \"FVC\")\n",
    "\n",
    "# colors = []\n",
    "\n",
    "# for i in fvc_color_map.values():\n",
    "#   colors.append((i[2]/255, i[1]/255, i[0]/255))\n",
    "\n",
    "# print(colors)\n",
    "\n",
    "# 创建 ListedColormap 对象\n",
    "# cmap = mcolors.ListedColormap(colors)\n",
    "cmap = get_listed_colormap(map_type)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hO3QOGkKQrO_",
    "outputId": "d45e07df-8b4f-4572-807e-07759f9689a1"
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QkexdlP3Er4B",
    "outputId": "bdc53e1d-8c4e-4d85-f4de-813abefda0f2"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_heatmap_square(data):\n",
    "    \"\"\"\n",
    "    绘制一个二维NumPy数组的热力图，每个数据点为正方形。\n",
    "\n",
    "    Args:\n",
    "        data: 二维NumPy数组。\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    # im = ax.imshow(data, cmap='RdYlGn')  # 选择合适的颜色映射\n",
    "    im = ax.imshow(data, cmap=cmap)  # 选择合适的颜色映射\n",
    "\n",
    "    # 隐藏坐标轴\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    # 设置纵横比，使单元格为正方形\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    # 添加颜色条\n",
    "    fig.colorbar(im, ax=ax)\n",
    "    plt.tight_layout()  # 调整布局，防止颜色条被裁剪\n",
    "    plt.show()\n",
    "\n",
    "# plot_heatmap_square(latest_15_years_data[-5])\n",
    "# plot_heatmap_square(latest_15_years_data[-4])\n",
    "# plot_heatmap_square(latest_15_years_data[-3])\n",
    "# plot_heatmap_square(latest_15_years_data[-2])\n",
    "plot_heatmap_square(latest_15_years_data[-1])\n",
    "plot_heatmap_square(predicted_map)\n",
    "\n",
    "print(latest_15_years_data[-1].min(), latest_15_years_data[-1].max())\n",
    "unique_values, counts = np.unique(latest_15_years_data[-1], return_counts=True)\n",
    "print(dict(zip(unique_values, counts)))\n",
    "print(predicted_map.min(), predicted_map.max())\n",
    "unique_values, counts = np.unique(predicted_map, return_counts=True)\n",
    "print(dict(zip(unique_values, counts)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "B8N4CjgnWtg5",
    "outputId": "d8b30818-5bf6-4484-8a04-ba87ab9e4796"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_heatmap_square(data):\n",
    "    \"\"\"\n",
    "    绘制一个二维NumPy数组的热力图，每个数据点为正方形。\n",
    "\n",
    "    Args:\n",
    "        data: 二维NumPy数组。\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(data, cmap='RdYlGn')  # 选择合适的颜色映射\n",
    "    # im = ax.imshow(data, cmap=cmap)  # 选择合适的颜色映射\n",
    "\n",
    "    # 隐藏坐标轴\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    # 设置纵横比，使单元格为正方形\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    # 添加颜色条\n",
    "    fig.colorbar(im, ax=ax)\n",
    "    plt.tight_layout()  # 调整布局，防止颜色条被裁剪\n",
    "    plt.show()\n",
    "\n",
    "# plot_heatmap_square(latest_15_years_data[-5])\n",
    "# plot_heatmap_square(latest_15_years_data[-4])\n",
    "# plot_heatmap_square(latest_15_years_data[-3])\n",
    "# plot_heatmap_square(latest_15_years_data[-2])\n",
    "plot_heatmap_square(latest_15_years_data[-1])\n",
    "plot_heatmap_square(predicted_map)\n",
    "\n",
    "print(latest_15_years_data[-1].min(), latest_15_years_data[-1].max())\n",
    "unique_values, counts = np.unique(latest_15_years_data[-1], return_counts=True)\n",
    "print(dict(zip(unique_values, counts)))\n",
    "print(predicted_map.min(), predicted_map.max())\n",
    "unique_values, counts = np.unique(predicted_map, return_counts=True)\n",
    "print(dict(zip(unique_values, counts)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-KvVSYFBdv7n"
   },
   "source": [
    "np.savez_compressed('outputs/RSEI_predicted_map.npz', predicted_map=predicted_map)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSfepf3K8ICj"
   },
   "source": [
    "# graphs"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "K_EKUMdz8QYc",
    "outputId": "bec8a879-d43d-4224-87eb-16950bb1637a"
   },
   "source": [
    "# 导入必要的包\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from google.colab.patches import cv2_imshow\n",
    "import cv2\n",
    "\n",
    "\n",
    "fvc_color_map = {\n",
    "    0: [0, 0, 0],  # 空\n",
    "    1: [0, 56, 168],  # L\n",
    "    2: [0, 115, 38],  # H\n",
    "    3: [82, 142, 249],  # RL\n",
    "    4: [103, 203, 134],  # RH\n",
    "    5: [190, 255, 255],  # M\n",
    "    6: [255, 255, 255],  # 白色像素\n",
    "}\n",
    "\n",
    "lulc_color_map = {\n",
    "    0: [0, 0, 0],  # 空\n",
    "    1: [115, 255, 255],  # Cropland\n",
    "    2: [0, 168, 112],  # Forest\n",
    "    3: [190, 255, 233],  # Grassland\n",
    "    4: [230, 92, 0],  # Water\n",
    "    5: [0, 76, 230],  # Impervious\n",
    "    6: [52, 52, 52],  # Barren\n",
    "    7: [204, 204, 204],  # Snow/Ice\n",
    "    8: [255, 255, 255],  # 白色像素\n",
    "}\n",
    "\n",
    "rsei_color_map = {\n",
    "    0: [0, 0, 0],  # 空\n",
    "    1: [0, 0, 255],  # Poor\n",
    "    2: [0, 128, 255],  # Fair\n",
    "    3: [0, 255, 255],  # Moderate\n",
    "    4: [0, 212, 141],  # Good\n",
    "    5: [0, 168, 56],  # Excellent\n",
    "    6: [255, 255, 255],  # 白色像素\n",
    "}\n",
    "\n",
    "map_type_map = {\n",
    "    'FVC': fvc_color_map,\n",
    "    'LULC': lulc_color_map,\n",
    "    'RSEI': rsei_color_map,\n",
    "}\n",
    "\n",
    "def img_2d_to_3d_vector(int_image, map_type):\n",
    "    \"\"\"\n",
    "    将整数表示的图像转换为RGB图像\n",
    "\n",
    "    :param int_image: h*w 的图像np数组，表示整数图像\n",
    "    :param map_type: 字符串，(fvc/lulc/rsei)\n",
    "    :return: h*w*3 的图像np数组，表示RGB图像。返回None如果颜色映射中没有找到对应的颜色。\n",
    "    \"\"\"\n",
    "    h, w = int_image.shape\n",
    "    try:\n",
    "        color_map = map_type_map[map_type]\n",
    "        rgb_values = np.array(list(color_map.values()))\n",
    "        int_values = np.array(list(color_map.keys()))\n",
    "\n",
    "        # 创建一个与int_image形状相同的数组，用于存储RGB值\n",
    "        rgb_image = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "        # 使用广播和np.where进行向量化操作\n",
    "        for i, int_val in enumerate(int_values):\n",
    "            rgb_image[int_image == int_val] = rgb_values[i]\n",
    "        rgb_image = background_2_white(rgb_image, 20)\n",
    "        return rgb_image\n",
    "    except KeyError:\n",
    "        print(\"颜色映射中没有找到对应的颜色。\")\n",
    "        return None\n",
    "\n",
    "def background_2_white(image, line_width):\n",
    "    # Step 1: 创建黑色部分的蒙版\n",
    "    # 黑色像素定义为所有通道都为 0\n",
    "    mask = np.all(image == [0, 0, 0], axis=-1).astype(np.uint8)  # 二值蒙版，黑色为1\n",
    "\n",
    "    # Step 2: 腐蚀蒙版\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (line_width, line_width))  # 定义腐蚀核\n",
    "    eroded_mask = cv2.erode(mask, kernel, iterations=1)  # 腐蚀操作\n",
    "\n",
    "    # Step 3: 替换蒙版区域为白色\n",
    "    # 将腐蚀后的蒙版区域设为白色\n",
    "    result_image = image.copy()\n",
    "    result_image[eroded_mask == 1] = [255, 255, 255]  # 替换为白色\n",
    "    return result_image\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_dict = {\n",
    "    \"CNN\": PureCNNModel(map_type=map_type),\n",
    "    \"LSTM\": PureLSTMModel(map_type=map_type),\n",
    "    \"CNNLSTM\": CNN_LSTM_Model(map_type=map_type),\n",
    "    \"Attention\": CNN_LSTM_Attention_Model(map_type=map_type),\n",
    "    \"ViT_Trans\": ViTTransformer(map_type=map_type),\n",
    "    \"ViT_LSTM\": ViTLSTM(map_type=map_type)\n",
    "}\n",
    "\n",
    "model_predict_maps = {'CNN': None, 'LSTM': None, 'CNNLSTM': None, 'Attention': None}\n",
    "\n",
    "# 载入数据并提取最后15年的数据\n",
    "fvc_data = np.load(f'{map_type}.npz')['arr_0']\n",
    "mask = np.load('whole_mask.npz')['arr_0']\n",
    "latest_15_years_data = fvc_data[-15:]  # 提取最后15年的数据，形状为 (15, 4416, 5786)\n",
    "\n",
    "predicted_map = np.zeros(latest_15_years_data.shape[1:])  # 初始化一个数组来保存预测结果\n",
    "\n",
    "mask = np.load('whole_mask.npz')['arr_0']\n",
    "\n",
    "# 设置区域大小\n",
    "region_size = 10\n",
    "offset = region_size // 2\n",
    "height, width = latest_15_years_data.shape[1:]\n",
    "\n",
    "\n",
    "indices = np.nonzero(mask[offset:height - offset, offset:width - offset])\n",
    "indices = list(zip(indices[0] + offset, indices[1] + offset))\n",
    "\n",
    "\n",
    "for model_type in ['CNN', 'LSTM', 'CNNLSTM', 'Attention']:\n",
    "  print(model_type)\n",
    "  # 加载保存的模型\n",
    "  model = model_dict[model_type].to(device)\n",
    "  print(f'models/{map_type}/{model_type}.pth')\n",
    "  model.load_state_dict(torch.load(f'models/{map_type}/{model_type}.pth', weights_only=True))\n",
    "\n",
    "  model.eval()  # 切换模型到评估模式\n",
    "  # 批量大小\n",
    "  batch_size = 1024 * 8  # 可以尝试调整批量大小，根据设备内存情况选择合适的数值\n",
    "\n",
    "  # 初始化结果数组\n",
    "  model_predict_maps[model_type] = np.zeros(latest_15_years_data.shape[1:], dtype=np.uint8)\n",
    "\n",
    "  # 将 indices 划分为批次\n",
    "  batches = [indices[i:i + batch_size] for i in range(0, len(indices), batch_size)]\n",
    "\n",
    "  # 遍历每个批次\n",
    "  for batch in tqdm(batches):\n",
    "      # 构造批量输入\n",
    "      input_batch = []\n",
    "      for i, j in batch:\n",
    "          input_data = latest_15_years_data[:, i - offset:i + offset + 1, j - offset:j + offset + 1]\n",
    "          input_batch.append(input_data)\n",
    "\n",
    "      # 转换为 Tensor 并移动到设备\n",
    "      input_tensor = torch.tensor(np.array(input_batch), dtype=torch.float32).to(device)  # 形状为 (batch_size, 15, 11, 11)\n",
    "\n",
    "      # 执行批量预测\n",
    "      with torch.no_grad():\n",
    "          outputs = model(input_tensor)\n",
    "          # 去除白色像素\n",
    "          outputs = outputs[:, :-1]\n",
    "          _, predicted_classes = torch.max(outputs, 1)  # 获取预测的类别\n",
    "          # print(outputs)\n",
    "          # print(outputs[:-1])\n",
    "\n",
    "      # 将预测结果写入预测地图\n",
    "      for (i, j), predicted_class in zip(batch, predicted_classes):\n",
    "          predicted_map[i, j] = predicted_class.item() + 1  # 提取数值并写入最终结果\n",
    "\n",
    "  # 画图\n",
    "  rgb_image = img_2d_to_3d_vector(predicted_map, map_type)\n",
    "  # cv2_imshow(img_2d_to_3d_vector(latest_15_years_data[-1], map_type))\n",
    "  # cv2_imshow(img_2d_to_3d_vector(latest_15_years_data[-2], map_type))\n",
    "  cv2_imshow(rgb_image)\n",
    "  if model_type == 'CNN':\n",
    "    cv2.imwrite(f'outputs/{map_type}_2023_predicted_map.png', img_2d_to_3d_vector(latest_15_years_data[-1], map_type))\n",
    "    cv2.imwrite(f'outputs/{map_type}_2022_predicted_map.png', img_2d_to_3d_vector(latest_15_years_data[-2], map_type))\n",
    "    cv2.imwrite(f'outputs/{map_type}_2021_predicted_map.png', img_2d_to_3d_vector(latest_15_years_data[-3], map_type))\n",
    "    cv2.imwrite(f'outputs/{map_type}_2020_predicted_map.png', img_2d_to_3d_vector(latest_15_years_data[-4], map_type))\n",
    "  cv2.imwrite(f'outputs/{map_type}_{model_type}_predicted_map.png', rgb_image)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "J8jKdzvW8bHa"
   },
   "source": [
    "\n",
    "\n",
    "rgb_image = img_2d_to_3d_vector(predicted_map, map_type)\n",
    "cv2_imshow(img_2d_to_3d_vector(latest_15_years_data[-1], map_type))\n",
    "cv2_imshow(img_2d_to_3d_vector(latest_15_years_data[-2], map_type))\n",
    "cv2_imshow(rgb_image)\n",
    "cv2.imwrite(f'outputs/{map_type}_{model_type}_predicted_map.png', rgb_image)\n",
    "\n",
    "rgb_image = img_2d_to_3d_vector(predicted_map, map_type)\n",
    "cv2_imshow(img_2d_to_3d_vector(latest_15_years_data[-1], map_type))\n",
    "cv2_imshow(img_2d_to_3d_vector(latest_15_years_data[-2], map_type))\n",
    "cv2_imshow(rgb_image)\n",
    "cv2.imwrite(f'outputs/{map_type}_{model_type}_predicted_map.png', rgb_image)\n",
    "\n",
    "rgb_image = img_2d_to_3d_vector(predicted_map, map_type)\n",
    "cv2_imshow(img_2d_to_3d_vector(latest_15_years_data[-1], map_type))\n",
    "cv2_imshow(img_2d_to_3d_vector(latest_15_years_data[-2], map_type))\n",
    "cv2_imshow(rgb_image)\n",
    "cv2.imwrite(f'outputs/{map_type}_{model_type}_predicted_map.png', rgb_image)\n",
    "\n",
    "rgb_image = img_2d_to_3d_vector(predicted_map, map_type)\n",
    "cv2_imshow(img_2d_to_3d_vector(latest_15_years_data[-1], map_type))\n",
    "cv2_imshow(img_2d_to_3d_vector(latest_15_years_data[-2], map_type))\n",
    "cv2_imshow(rgb_image)\n",
    "cv2.imwrite(f'outputs/{map_type}_{model_type}_predicted_map.png', rgb_image)\n",
    "\n",
    "rgb_image = img_2d_to_3d_vector(predicted_map, map_type)\n",
    "cv2_imshow(img_2d_to_3d_vector(latest_15_years_data[-1], map_type))\n",
    "cv2_imshow(img_2d_to_3d_vector(latest_15_years_data[-2], map_type))\n",
    "cv2_imshow(rgb_image)\n",
    "cv2.imwrite(f'outputs/{map_type}_{model_type}_predicted_map.png', rgb_image)\n",
    "\n",
    "rgb_image = img_2d_to_3d_vector(predicted_map, map_type)\n",
    "cv2_imshow(img_2d_to_3d_vector(latest_15_years_data[-1], map_type))\n",
    "cv2_imshow(img_2d_to_3d_vector(latest_15_years_data[-2], map_type))\n",
    "cv2_imshow(rgb_image)\n",
    "cv2.imwrite(f'outputs/{map_type}_{model_type}_predicted_map.png', rgb_image)\n",
    "\n",
    "rgb_image = img_2d_to_3d_vector(predicted_map, map_type)\n",
    "cv2_imshow(img_2d_to_3d_vector(latest_15_years_data[-1], map_type))\n",
    "cv2_imshow(img_2d_to_3d_vector(latest_15_years_data[-2], map_type))\n",
    "cv2_imshow(rgb_image)\n",
    "cv2.imwrite(f'outputs/{map_type}_{model_type}_predicted_map.png', rgb_image)\n",
    "\n",
    "rgb_image = img_2d_to_3d_vector(predicted_map, map_type)\n",
    "cv2_imshow(img_2d_to_3d_vector(latest_15_years_data[-1], map_type))\n",
    "cv2_imshow(img_2d_to_3d_vector(latest_15_years_data[-2], map_type))\n",
    "cv2_imshow(rgb_image)\n",
    "cv2.imwrite(f'outputs/{map_type}_{model_type}_predicted_map.png', rgb_image)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "d170e34cf84b4e6d811f3556c74ea538": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DropdownModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "CNN",
       "LSTM",
       "CNNLSTM",
       "Attention",
       "ViT_Trans",
       "ViT_LSTM"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "Model:",
      "description_tooltip": null,
      "disabled": false,
      "index": 0,
      "layout": "IPY_MODEL_a4e1b6941394474cbf357949a6ae423d",
      "style": "IPY_MODEL_30599db4a19242f396817949719f7ccc"
     }
    },
    "a4e1b6941394474cbf357949a6ae423d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30599db4a19242f396817949719f7ccc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "be3cb6229dc544689098f92bf6048e8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DropdownModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "FVC",
       "LULC",
       "RSEI"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "Map Type:",
      "description_tooltip": null,
      "disabled": false,
      "index": 0,
      "layout": "IPY_MODEL_de3860177e0940048a8401af436add2d",
      "style": "IPY_MODEL_b27606bf646d4ac7bb22ca534e62be91"
     }
    },
    "de3860177e0940048a8401af436add2d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b27606bf646d4ac7bb22ca534e62be91": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dabdc29e9d9b46ceafde530e293ae2a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ButtonModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Confirm",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_a05dd1c9fe1f4ad7a88c44a965cadc2c",
      "style": "IPY_MODEL_284c2506a24b47a9a8d9de494379aa98",
      "tooltip": ""
     }
    },
    "a05dd1c9fe1f4ad7a88c44a965cadc2c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "284c2506a24b47a9a8d9de494379aa98": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ButtonStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "24d50d926d414d2e8feed09f80e1c449": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bc01875cbac941cf8614de49d2437722",
       "IPY_MODEL_3eae1c1dce084203aee4ff79e1e16c1e",
       "IPY_MODEL_1e8e90ba89234e5ebd90a9bea285d44e"
      ],
      "layout": "IPY_MODEL_e035909437034f2e88eb2821a1f6da14"
     }
    },
    "bc01875cbac941cf8614de49d2437722": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49afc2ef49c7412cbe57a13d2df93d41",
      "placeholder": "​",
      "style": "IPY_MODEL_6a91af40b4354f03b12bc896977600bc",
      "value": "Calculating weight...: 100%"
     }
    },
    "3eae1c1dce084203aee4ff79e1e16c1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a993cc466ca94b42ab529dc406f94de7",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1d5a6557cf0846d2811911c39ad8325f",
      "value": 5
     }
    },
    "1e8e90ba89234e5ebd90a9bea285d44e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ff4dc4397d447cfa6c7bf12ba40b627",
      "placeholder": "​",
      "style": "IPY_MODEL_2337f72d267845bcadc6617ceb2dd154",
      "value": " 5/5 [00:02&lt;00:00,  2.44it/s]"
     }
    },
    "e035909437034f2e88eb2821a1f6da14": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49afc2ef49c7412cbe57a13d2df93d41": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a91af40b4354f03b12bc896977600bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a993cc466ca94b42ab529dc406f94de7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d5a6557cf0846d2811911c39ad8325f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7ff4dc4397d447cfa6c7bf12ba40b627": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2337f72d267845bcadc6617ceb2dd154": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "42a6a5af31734b1b97d6144fefd10614": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_77709b3edb264d16a5a7b065daa3f8ef",
       "IPY_MODEL_f9f17e309db64c95b58240c805de1bdb",
       "IPY_MODEL_fafb6e07fe5141d69c9403e859fc5ba1"
      ],
      "layout": "IPY_MODEL_97cd252d78c54533b3762095a4872907"
     }
    },
    "77709b3edb264d16a5a7b065daa3f8ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6ed26607130489f9e9a8982855bacc8",
      "placeholder": "​",
      "style": "IPY_MODEL_1e20b10c753641b09c97aa862d261d24",
      "value": "Assigning weight...: 100%"
     }
    },
    "f9f17e309db64c95b58240c805de1bdb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c8496f4007f4a93bd7c877aa359f542",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_17ce8b44829f4f799eeceea2d3150051",
      "value": 5
     }
    },
    "fafb6e07fe5141d69c9403e859fc5ba1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a418faefb2ce450a8b8b92808fef2e06",
      "placeholder": "​",
      "style": "IPY_MODEL_b3dd574545174b1ab696b6526b34907b",
      "value": " 5/5 [00:02&lt;00:00,  1.73it/s]"
     }
    },
    "97cd252d78c54533b3762095a4872907": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6ed26607130489f9e9a8982855bacc8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e20b10c753641b09c97aa862d261d24": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1c8496f4007f4a93bd7c877aa359f542": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17ce8b44829f4f799eeceea2d3150051": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a418faefb2ce450a8b8b92808fef2e06": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3dd574545174b1ab696b6526b34907b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a95f7b4e252474c8583eb7fd88a6c46": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e3c736e0ac6744f68d25edbdac1b1704",
       "IPY_MODEL_d5a75c307e274cee92b7ceaaf5cd9f46",
       "IPY_MODEL_bc84a83c96504941a96fea60c95398ec"
      ],
      "layout": "IPY_MODEL_d8022dcda62a4531ad867e7d53edd0a7"
     }
    },
    "e3c736e0ac6744f68d25edbdac1b1704": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e55bda5c00f64ca4ad2d8571079da589",
      "placeholder": "​",
      "style": "IPY_MODEL_891096e8eb894989a6cc7daf6ec585e5",
      "value": "100%"
     }
    },
    "d5a75c307e274cee92b7ceaaf5cd9f46": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f04d84742cfb4b559782b08d5ce1d84d",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0a2feb40efc54bbbbd46719933c900a5",
      "value": 7
     }
    },
    "bc84a83c96504941a96fea60c95398ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae0af5ad164e4a4a8c33e8500e6b9b35",
      "placeholder": "​",
      "style": "IPY_MODEL_48eb7401a6f04d5eb30c506c85390124",
      "value": " 7/7 [00:05&lt;00:00,  1.08it/s]"
     }
    },
    "d8022dcda62a4531ad867e7d53edd0a7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e55bda5c00f64ca4ad2d8571079da589": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "891096e8eb894989a6cc7daf6ec585e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f04d84742cfb4b559782b08d5ce1d84d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a2feb40efc54bbbbd46719933c900a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ae0af5ad164e4a4a8c33e8500e6b9b35": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48eb7401a6f04d5eb30c506c85390124": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0e962ba7126042e79fc4535ce21458dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_554ba37f89ce4d0097b472f3e1864335",
       "IPY_MODEL_850fb100de844941b2ffaf1955f9fc8a",
       "IPY_MODEL_a5aa2ebab9a549ce8613d9ab0ba1f030"
      ],
      "layout": "IPY_MODEL_3d0409f839ca43fd8575942084eb585b"
     }
    },
    "554ba37f89ce4d0097b472f3e1864335": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_193c22694a5c4e859c7bd14ecac71662",
      "placeholder": "​",
      "style": "IPY_MODEL_bd8cd3291bf744f8b50520ef83c8fe79",
      "value": "100%"
     }
    },
    "850fb100de844941b2ffaf1955f9fc8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c3294508c8d4422b3cfe9fa6e6c0cca",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bc0229dffa3c4990a3fd52fef0af273b",
      "value": 7
     }
    },
    "a5aa2ebab9a549ce8613d9ab0ba1f030": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4db41b167ab84c96babcfea4e07673fa",
      "placeholder": "​",
      "style": "IPY_MODEL_a918989cc1404b05974f1206e4c093d9",
      "value": " 7/7 [00:06&lt;00:00,  1.03s/it]"
     }
    },
    "3d0409f839ca43fd8575942084eb585b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "193c22694a5c4e859c7bd14ecac71662": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd8cd3291bf744f8b50520ef83c8fe79": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9c3294508c8d4422b3cfe9fa6e6c0cca": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc0229dffa3c4990a3fd52fef0af273b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4db41b167ab84c96babcfea4e07673fa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a918989cc1404b05974f1206e4c093d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6df8947776df46609991d4be444de7a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_127332dab12848f59c42a5133ae2c9c0",
       "IPY_MODEL_63f14af70e694cddba182c25f66c642a",
       "IPY_MODEL_618f52167ffc48fab4341bcf5103e2d8"
      ],
      "layout": "IPY_MODEL_580ed1ee144844fc91c678bec38c6b99"
     }
    },
    "127332dab12848f59c42a5133ae2c9c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d044fe1654a40c6b077cc9b1fc40390",
      "placeholder": "​",
      "style": "IPY_MODEL_443cde3e8b964b818c1399fe30ac9d42",
      "value": "100%"
     }
    },
    "63f14af70e694cddba182c25f66c642a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f93abba8ce54f3880d1f213baed63b6",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a3a6993b1d9e4f4e9ea4d359408e01fb",
      "value": 7
     }
    },
    "618f52167ffc48fab4341bcf5103e2d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b0261738dcd4cb7b7d54a41760fdcc6",
      "placeholder": "​",
      "style": "IPY_MODEL_30a00ad147e24dbaa9f7cf91d9485b75",
      "value": " 7/7 [00:07&lt;00:00,  1.14it/s]"
     }
    },
    "580ed1ee144844fc91c678bec38c6b99": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d044fe1654a40c6b077cc9b1fc40390": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "443cde3e8b964b818c1399fe30ac9d42": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4f93abba8ce54f3880d1f213baed63b6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3a6993b1d9e4f4e9ea4d359408e01fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4b0261738dcd4cb7b7d54a41760fdcc6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30a00ad147e24dbaa9f7cf91d9485b75": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "64ad90e33a2544a8a33ff71ff67618b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bc193aeb2b9d4170aade328a05085f07",
       "IPY_MODEL_bcdab4a336df49458101bd5875fa4050",
       "IPY_MODEL_91d62dd31bf34f13a910c6517b3c6aac"
      ],
      "layout": "IPY_MODEL_1839ac209ec147a3bb3b58b5c32a6fa8"
     }
    },
    "bc193aeb2b9d4170aade328a05085f07": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eba2d07c1f964ce4ad9d50bb8fdc7d04",
      "placeholder": "​",
      "style": "IPY_MODEL_ca324e5a48484a248b2ce2ffe55c3fad",
      "value": "100%"
     }
    },
    "bcdab4a336df49458101bd5875fa4050": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b62835cf31984f56bec062e4ed7e83fd",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d5022fdf78874478845fc881552cbd06",
      "value": 7
     }
    },
    "91d62dd31bf34f13a910c6517b3c6aac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f73dd73221f42479b1f02b1ea7a0537",
      "placeholder": "​",
      "style": "IPY_MODEL_c889807ee6c24d11aa3a0ad101c66499",
      "value": " 7/7 [00:06&lt;00:00,  1.01it/s]"
     }
    },
    "1839ac209ec147a3bb3b58b5c32a6fa8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eba2d07c1f964ce4ad9d50bb8fdc7d04": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca324e5a48484a248b2ce2ffe55c3fad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b62835cf31984f56bec062e4ed7e83fd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5022fdf78874478845fc881552cbd06": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4f73dd73221f42479b1f02b1ea7a0537": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c889807ee6c24d11aa3a0ad101c66499": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
